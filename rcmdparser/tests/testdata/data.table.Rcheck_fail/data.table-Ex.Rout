
R version 3.5.2 (2018-12-20) -- "Eggshell Igloo"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin15.6.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "data.table"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> base::assign(".ExTimings", "data.table-Ex.timings", pos = 'CheckExEnv')
> base::cat("name\tuser\tsystem\telapsed\n", file=base::get(".ExTimings", pos = 'CheckExEnv'))
> base::assign(".format_ptime",
+ function(x) {
+   if(!is.na(x[4L])) x[1L] <- x[1L] + x[4L]
+   if(!is.na(x[5L])) x[2L] <- x[2L] + x[5L]
+   options(OutDec = '.')
+   format(x[1L:3L], digits = 7L)
+ },
+ pos = 'CheckExEnv')
> 
> ### * </HEADER>
> library('data.table')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("IDateTime")
> ### * IDateTime
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: IDateTime
> ### Title: Integer based date class
> ### Aliases: IDate as.IDate ITime as.ITime IDateTime as.character.ITime
> ###   as.Date.IDate as.IDate.Date as.IDate.default as.ITime.character
> ###   as.ITime.default as.ITime.POSIXlt as.ITime.times as.list.IDate
> ###   as.POSIXct.IDate as.POSIXct.ITime as.POSIXlt.ITime c.IDate cut.IDate
> ###   format.ITime IDateTime.default mean.IDate print.ITime rep.IDate
> ###   rep.ITime round.IDate seq.IDate split.IDate second minute hour yday
> ###   wday mday week isoweek month quarter year IDate-class ITime-class
> ### Keywords: utilities
> 
> ### ** Examples
> 
> 
> # create IDate:
> (d <- as.IDate("2001-01-01"))
[1] "2001-01-01"
> 
> # S4 coercion also works
> identical(as.IDate("2001-01-01"), as("2001-01-01", "IDate"))
[1] TRUE
> 
> # create ITime:
> (t <- as.ITime("10:45"))
[1] "10:45:00"
> 
> # S4 coercion also works
> identical(as.ITime("10:45"), as("10:45", "ITime"))
[1] TRUE
> 
> (t <- as.ITime("10:45:04"))
[1] "10:45:04"
> 
> (t <- as.ITime("10:45:04", format = "%H:%M:%S"))
[1] "10:45:04"
> 
> as.POSIXct("2001-01-01") + as.ITime("10:45")
[1] "2001-01-01 10:45:00 EST"
> 
> datetime <- seq(as.POSIXct("2001-01-01"), as.POSIXct("2001-01-03"), by = "5 hour")
> (af <- data.table(IDateTime(datetime), a = rep(1:2, 5), key = "a,idate,itime"))
         idate    itime a
 1: 2001-01-01 00:00:00 1
 2: 2001-01-01 10:00:00 1
 3: 2001-01-01 20:00:00 1
 4: 2001-01-02 06:00:00 1
 5: 2001-01-02 16:00:00 1
 6: 2001-01-01 05:00:00 2
 7: 2001-01-01 15:00:00 2
 8: 2001-01-02 01:00:00 2
 9: 2001-01-02 11:00:00 2
10: 2001-01-02 21:00:00 2
> 
> af[, mean(a), by = "itime"]
       itime V1
 1: 00:00:00  1
 2: 10:00:00  1
 3: 20:00:00  1
 4: 06:00:00  1
 5: 16:00:00  1
 6: 05:00:00  2
 7: 15:00:00  2
 8: 01:00:00  2
 9: 11:00:00  2
10: 21:00:00  2
> af[, mean(a), by = list(hour = hour(itime))]
    hour V1
 1:    0  1
 2:   10  1
 3:   20  1
 4:    6  1
 5:   16  1
 6:    5  2
 7:   15  2
 8:    1  2
 9:   11  2
10:   21  2
> af[, mean(a), by = list(wday = factor(weekdays(idate)))]
      wday  V1
1:  Monday 1.4
2: Tuesday 1.6
> af[, mean(a), by = list(wday = wday(idate))]
   wday  V1
1:    2 1.4
2:    3 1.6
> 
> as.POSIXct(af$idate)
 [1] "2001-01-01 UTC" "2001-01-01 UTC" "2001-01-01 UTC" "2001-01-02 UTC"
 [5] "2001-01-02 UTC" "2001-01-01 UTC" "2001-01-01 UTC" "2001-01-02 UTC"
 [9] "2001-01-02 UTC" "2001-01-02 UTC"
> as.POSIXct(af$idate, time = af$itime)
 [1] "2001-01-01 00:00:00 UTC" "2001-01-01 10:00:00 UTC"
 [3] "2001-01-01 20:00:00 UTC" "2001-01-02 06:00:00 UTC"
 [5] "2001-01-02 16:00:00 UTC" "2001-01-01 05:00:00 UTC"
 [7] "2001-01-01 15:00:00 UTC" "2001-01-02 01:00:00 UTC"
 [9] "2001-01-02 11:00:00 UTC" "2001-01-02 21:00:00 UTC"
> as.POSIXct(af$idate, af$itime)
 [1] "2001-01-01 00:00:00 UTC" "2001-01-01 10:00:00 UTC"
 [3] "2001-01-01 20:00:00 UTC" "2001-01-02 06:00:00 UTC"
 [5] "2001-01-02 16:00:00 UTC" "2001-01-01 05:00:00 UTC"
 [7] "2001-01-01 15:00:00 UTC" "2001-01-02 01:00:00 UTC"
 [9] "2001-01-02 11:00:00 UTC" "2001-01-02 21:00:00 UTC"
> as.POSIXct(af$idate, time = af$itime, tz = "GMT")
 [1] "2001-01-01 00:00:00 GMT" "2001-01-01 10:00:00 GMT"
 [3] "2001-01-01 20:00:00 GMT" "2001-01-02 06:00:00 GMT"
 [5] "2001-01-02 16:00:00 GMT" "2001-01-01 05:00:00 GMT"
 [7] "2001-01-01 15:00:00 GMT" "2001-01-02 01:00:00 GMT"
 [9] "2001-01-02 11:00:00 GMT" "2001-01-02 21:00:00 GMT"
> 
> as.POSIXct(af$itime, af$idate)
 [1] "2001-01-01 00:00:00 UTC" "2001-01-01 10:00:00 UTC"
 [3] "2001-01-01 20:00:00 UTC" "2001-01-02 06:00:00 UTC"
 [5] "2001-01-02 16:00:00 UTC" "2001-01-01 05:00:00 UTC"
 [7] "2001-01-01 15:00:00 UTC" "2001-01-02 01:00:00 UTC"
 [9] "2001-01-02 11:00:00 UTC" "2001-01-02 21:00:00 UTC"
> as.POSIXct(af$itime) # uses today's date
 [1] "2019-03-01 00:00:00 UTC" "2019-03-01 10:00:00 UTC"
 [3] "2019-03-01 20:00:00 UTC" "2019-03-01 06:00:00 UTC"
 [5] "2019-03-01 16:00:00 UTC" "2019-03-01 05:00:00 UTC"
 [7] "2019-03-01 15:00:00 UTC" "2019-03-01 01:00:00 UTC"
 [9] "2019-03-01 11:00:00 UTC" "2019-03-01 21:00:00 UTC"
> 
> (seqdates <- seq(as.IDate("2001-01-01"), as.IDate("2001-08-03"), by = "3 weeks"))
 [1] "2001-01-01" "2001-01-22" "2001-02-12" "2001-03-05" "2001-03-26"
 [6] "2001-04-16" "2001-05-07" "2001-05-28" "2001-06-18" "2001-07-09"
[11] "2001-07-30"
> round(seqdates, "months")
 [1] "2001-01-01" "2001-01-01" "2001-02-01" "2001-03-01" "2001-03-01"
 [6] "2001-04-01" "2001-05-01" "2001-05-01" "2001-06-01" "2001-07-01"
[11] "2001-07-01"
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("IDateTime", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("J")
> ### * J
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: J
> ### Title: Creates a Join data table
> ### Aliases: J CJ SJ
> ### Keywords: data
> 
> ### ** Examples
> 
> DT = data.table(A=5:1,B=letters[5:1])
> setkey(DT,B)    # re-orders table and marks it sorted.
> DT[J("b")]      # returns the 2nd row
   A B
1: 2 b
> DT[.("b")]      # same. Style of package plyr.
   A B
1: 2 b
> DT[list("b")]   # same
   A B
1: 2 b
> 
> # CJ usage examples
> CJ(c(5,NA,1), c(1,3,2)) # sorted and keyed data.table
   V1 V2
1: NA  1
2: NA  2
3: NA  3
4:  1  1
5:  1  2
6:  1  3
7:  5  1
8:  5  2
9:  5  3
> do.call(CJ, list(c(5,NA,1), c(1,3,2))) # same as above
   V1 V2
1: NA  1
2: NA  2
3: NA  3
4:  1  1
5:  1  2
6:  1  3
7:  5  1
8:  5  2
9:  5  3
> CJ(c(5,NA,1), c(1,3,2), sorted=FALSE) # same order as input, unkeyed
   V1 V2
1:  5  1
2:  5  3
3:  5  2
4: NA  1
5: NA  3
6: NA  2
7:  1  1
8:  1  3
9:  1  2
> # use for 'unique=' argument
> x = c(1,1,2)
> y = c(4,6,4)
> CJ(x, y) # output columns are automatically named 'x' and 'y'
   V1 V2
1:  1  4
2:  1  4
3:  1  4
4:  1  4
5:  1  6
6:  1  6
7:  2  4
8:  2  4
9:  2  6
> CJ(x, y, unique=TRUE) # unique(x) and unique(y) are computed automatically
   V1 V2
1:  1  4
2:  1  6
3:  2  4
4:  2  6
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("J", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("all.equal.data.table")
> ### * all.equal.data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: all.equal
> ### Title: Equality Test Between Two Data Tables
> ### Aliases: all.equal all.equal.data.table
> 
> ### ** Examples
> 
> dt1 <- data.table(A = letters[1:10], X = 1:10, key = "A")
> dt2 <- data.table(A = letters[5:14], Y = 1:10, key = "A")
> isTRUE(all.equal(dt1, dt1))
[1] TRUE
> is.character(all.equal(dt1, dt2))
[1] TRUE
> 
> # ignore.col.order
> x <- copy(dt1)
> y <- dt1[, .(X, A)]
> all.equal(x, y)
[1] "Different column order"
> all.equal(x, y, ignore.col.order = TRUE)
[1] TRUE
> 
> # ignore.row.order
> x <- setkeyv(copy(dt1), NULL)
> y <- dt1[sample(nrow(dt1))]
> all.equal(x, y)
[1] "Column 'A': 10 string mismatches"
> all.equal(x, y, ignore.row.order = TRUE)
[1] TRUE
> 
> # check.attributes
> x = copy(dt1)
> y = setkeyv(copy(dt1), NULL)
> all.equal(x, y)
[1] "Datasets has different keys. 'target': A. 'current' has no key."
> all.equal(x, y, check.attributes = FALSE)
[1] TRUE
> 
> # trim.levels
> x <- data.table(A = factor(letters[1:10])[1:4]) # 10 levels
> y <- data.table(A = factor(letters[1:5])[1:4]) # 5 levels
> all.equal(x, y, trim.levels = FALSE)
[1] "Column 'A': Levels not identical. No attempt to refactor because trim.levels is FALSE"
> all.equal(x, y, trim.levels = FALSE, check.attributes = FALSE)
[1] "Column 'A': Levels not identical. No attempt to refactor because trim.levels is FALSE"
> all.equal(x, y)
[1] TRUE
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("all.equal.data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("as.data.table")
> ### * as.data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: as.data.table
> ### Title: Coerce to data.table
> ### Aliases: as.data.table as.data.table.array as.data.table.matrix
> ###   as.data.table.list as.data.table.data.frame as.data.table.data.table
> ###   as.data.table.factor as.data.table.ordered as.data.table.integer
> ###   as.data.table.numeric as.data.table.logical as.data.table.character
> ###   as.data.table.Date is.data.table
> ### Keywords: data
> 
> ### ** Examples
> 
> nn = c(a=0.1, b=0.2, c=0.3, d=0.4)
> as.data.table(nn)
    nn
1: 0.1
2: 0.2
3: 0.3
4: 0.4
> as.data.table(nn, keep.rownames=TRUE)
   rn  nn
1:  a 0.1
2:  b 0.2
3:  c 0.3
4:  d 0.4
> as.data.table(nn, keep.rownames="rownames")
   rownames  nn
1:        a 0.1
2:        b 0.2
3:        c 0.3
4:        d 0.4
> 
> # char object not converted to factor
> cc = c(X="a", Y="b", Z="c")
> as.data.table(cc)
   cc
1:  a
2:  b
3:  c
> as.data.table(cc, keep.rownames=TRUE)
   rn cc
1:  X  a
2:  Y  b
3:  Z  c
> as.data.table(cc, keep.rownames="rownames")
   rownames cc
1:        X  a
2:        Y  b
3:        Z  c
> 
> mm = matrix(1:4, ncol=2, dimnames=list(c("r1", "r2"), c("c1", "c2")))
> as.data.table(mm)
   c1 c2
1:  1  3
2:  2  4
> as.data.table(mm, keep.rownames=TRUE)
   rn c1 c2
1: r1  1  3
2: r2  2  4
> as.data.table(mm, keep.rownames="rownames")
   rownames c1 c2
1:       r1  1  3
2:       r2  2  4
> 
> ll = list(a=1:2, b=3:4)
> as.data.table(ll)
   a b
1: 1 3
2: 2 4
> as.data.table(ll, keep.rownames=TRUE)
   a b
1: 1 3
2: 2 4
> as.data.table(ll, keep.rownames="rownames")
   a b
1: 1 3
2: 2 4
> 
> DF = data.frame(x=rep(c("x","y","z"),each=2), y=c(1,3,6), row.names=LETTERS[1:6])
> as.data.table(DF)
   x y
1: x 1
2: x 3
3: y 6
4: y 1
5: z 3
6: z 6
> as.data.table(DF, keep.rownames=TRUE)
   rn x y
1:  A x 1
2:  B x 3
3:  C y 6
4:  D y 1
5:  E z 3
6:  F z 6
> as.data.table(DF, keep.rownames="rownames")
   rownames x y
1:        A x 1
2:        B x 3
3:        C y 6
4:        D y 1
5:        E z 3
6:        F z 6
> 
> DT = data.table(x=rep(c("x","y","z"),each=2), y=c(1:6))
> as.data.table(DT)
   x y
1: x 1
2: x 2
3: y 3
4: y 4
5: z 5
6: z 6
> 
> ar = rnorm(27)
> ar[sample(27, 15)] = NA
> dim(ar) = c(3L,3L,3L)
> as.data.table(ar)
    V1 V2 V3       value
 1:  1  1  1 -0.62645381
 2:  1  1  2 -0.30538839
 3:  1  1  3  0.82122120
 4:  1  2  1  1.59528080
 5:  1  3  1  0.48742905
 6:  2  2  2 -2.21469989
 7:  2  2  3  0.07456498
 8:  2  3  2 -0.01619026
 9:  2  3  3 -0.05612874
10:  3  2  2  1.12493092
11:  3  2  3 -1.98935170
12:  3  3  2  0.94383621
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("as.data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("as.data.table.xts")
> ### * as.data.table.xts
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: as.data.table.xts
> ### Title: Efficient xts to as.data.table conversion
> ### Aliases: as.data.table.xts
> 
> ### ** Examples
> 
> if (requireNamespace("xts", quietly = TRUE)) {
+   data(sample_matrix, package = "xts")
+   sample.xts <- xts::as.xts(sample_matrix) # xts might not be attached on search path
+   # print head of xts
+   print(head(sample.xts))
+   # print data.table
+   print(as.data.table(sample.xts))
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("as.data.table.xts", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("as.matrix")
> ### * as.matrix
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: as.matrix
> ### Title: Convert a data.table to a matrix
> ### Aliases: as.matrix as.matrix.data.table
> ### Keywords: array
> 
> ### ** Examples
> 
> DT <- data.table(A = letters[1:10], X = 1:10, Y = 11:20)
> as.matrix(DT) # character matrix
      A   X    Y   
 [1,] "a" " 1" "11"
 [2,] "b" " 2" "12"
 [3,] "c" " 3" "13"
 [4,] "d" " 4" "14"
 [5,] "e" " 5" "15"
 [6,] "f" " 6" "16"
 [7,] "g" " 7" "17"
 [8,] "h" " 8" "18"
 [9,] "i" " 9" "19"
[10,] "j" "10" "20"
> as.matrix(DT, rownames = "A")
   X  Y
a  1 11
b  2 12
c  3 13
d  4 14
e  5 15
f  6 16
g  7 17
h  8 18
i  9 19
j 10 20
> as.matrix(DT, rownames = 1)
   X  Y
a  1 11
b  2 12
c  3 13
d  4 14
e  5 15
f  6 16
g  7 17
h  8 18
i  9 19
j 10 20
> as.matrix(DT, rownames = TRUE)
   X  Y
a  1 11
b  2 12
c  3 13
d  4 14
e  5 15
f  6 16
g  7 17
h  8 18
i  9 19
j 10 20
> 
> setkey(DT, A)
> as.matrix(DT, rownames = TRUE)
   X  Y
a  1 11
b  2 12
c  3 13
d  4 14
e  5 15
f  6 16
g  7 17
h  8 18
i  9 19
j 10 20
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("as.matrix", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("as.xts.data.table")
> ### * as.xts.data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: as.xts.data.table
> ### Title: Efficient data.table to xts conversion
> ### Aliases: as.xts.data.table
> 
> ### ** Examples
> 
> if (requireNamespace("xts", quietly = TRUE)) {
+   sample.dt <- data.table(date = as.Date((Sys.Date()-999):Sys.Date(),origin="1970-01-01"),
+                           quantity = sample(10:50,1000,TRUE),
+                           value = sample(100:1000,1000,TRUE))
+   # print data.table
+   print(sample.dt)
+   # print head of xts
+   print(head(as.xts.data.table(sample.dt))) # xts might not be attached on search path
+ }
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("as.xts.data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("assign")
> ### * assign
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: :=
> ### Title: Assignment by reference
> ### Aliases: := set
> ### Keywords: data
> 
> ### ** Examples
> 
> DT = data.table(a = LETTERS[c(3L,1:3)], b = 4:7)
> DT[, c := 8]                # add a numeric column, 8 for all rows
> DT[, d := 9L]               # add an integer column, 9L for all rows
> DT[, c := NULL]             # remove column c
> DT[2, d := -8L]             # subassign by reference to d; 2nd row is -8L now
> DT                          # DT changed by reference
   a b  d
1: C 4  9
2: A 5 -8
3: B 6  9
4: C 7  9
> DT[2, d := 10L][]           # shorthand for update and print
   a b  d
1: C 4  9
2: A 5 10
3: B 6  9
4: C 7  9
> 
> DT[b > 4, b := d * 2L]      # subassign to b with d*2L on those rows where b > 4 is TRUE
> DT[b > 4][, b := d * 2L]    # different from above. [, := ] is performed on the subset
>                             # which is an new (ephemeral) data.table. Result needs to be
>                             # assigned to a variable (using `<-`).
> 
> DT[, e := mean(d), by = a]  # add new column by group by reference
> DT["A", b := 0L, on = "a"]  # ad-hoc update of column b for group "A" using
> 			    # joins-as-subsets with binary search and 'on='
> # same as above but using keys
> setkey(DT, a)
> DT["A", b := 0L]            # binary search for group "A" and set column b using keys
> DT["B", f := mean(d)]       # subassign to new column, NA initialized
> 
> # Adding multiple columns
> ## by name
> DT[ , c('sin_d', 'log_e', 'cos_d') :=
+    .(sin(d), log(e), cos(d))]
> ## by patterned name
> DT[ , paste(c('sin', 'cos'), 'b', sep = '_') :=
+    .(sin(b), cos(b))]
> ## using lapply & .SD
> DT[ , paste0('tan_', c('b', 'd', 'e')) :=
+    lapply(.SD, tan), .SDcols = c('b', 'd', 'e')]
> ## using forced evaluation to disambguate a vector of names
> ##   and overwrite existing columns with their squares
> sq_cols = c('b', 'd', 'e')
> DT[ , (sq_cols) := lapply(.SD, `^`, 2L), .SDcols = sq_cols]
> ## by integer (NB: for robustness, it is not recommended
> ##   to use explicit integers to update/define columns)
> DT[ , c(2L, 3L, 4L) := .(sqrt(b), sqrt(d), sqrt(e))]
> ## by implicit integer
> DT[ , grep('a$', names(DT)) := tolower(a)]
> ## by implicit integer, using forced evaluation
> sq_col_idx = grep('d$', names(DT))
> DT[ , (sq_col_idx) := lapply(.SD, dnorm),
+    .SDcols = sq_col_idx]
> 
> ## Not run: 
> ##D # Speed example:
> ##D 
> ##D m = matrix(1, nrow = 2e6L, ncol = 100L)
> ##D DF = as.data.frame(m)
> ##D DT = as.data.table(m)
> ##D 
> ##D system.time(for (i in 1:1000) DF[i, 1] = i)
> ##D # 15.856 seconds
> ##D system.time(for (i in 1:1000) DT[i, V1 := i])
> ##D # 0.279 seconds  (57 times faster)
> ##D system.time(for (i in 1:1000) set(DT, i, 1L, i))
> ##D # 0.002 seconds  (7930 times faster, overhead of [.data.table is avoided)
> ##D 
> ##D # However, normally, we call [.data.table *once* on *large* data, not many times on small data.
> ##D # The above is to demonstrate overhead, not to recommend looping in this way. But the option
> ##D # of set() is there if you need it.
> ## End(Not run)
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("assign", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("between")
> ### * between
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: between
> ### Title: Convenience functions for range subsets.
> ### Aliases: between %between% inrange %inrange%
> ### Keywords: data
> 
> ### ** Examples
> 
> X = data.table(a=1:5, b=6:10, c=c(5:1))
> X[b %between% c(7,9)]
   a b c
1: 2 7 4
2: 3 8 3
3: 4 9 2
> X[between(b, 7, 9)] # same as above
   a b c
1: 2 7 4
2: 3 8 3
3: 4 9 2
> # NEW feature in v1.9.8, vectorised between
> X[c %between% list(a,b)]
   a b c
1: 1 6 5
2: 2 7 4
3: 3 8 3
> X[between(c, a, b)] # same as above
   a b c
1: 1 6 5
2: 2 7 4
3: 3 8 3
> X[between(c, a, b, incbounds=FALSE)] # open interval
   a b c
1: 1 6 5
2: 2 7 4
> 
> # inrange()
> Y = data.table(a=c(8,3,10,7,-10), val=runif(5))
> range = data.table(start = 1:5, end = 6:10)
> Y[a %inrange% range]
    a       val
1:  8 0.2655087
2:  3 0.3721239
3: 10 0.5728534
4:  7 0.9082078
> Y[inrange(a, range$start, range$end)] # same as above
    a       val
1:  8 0.2655087
2:  3 0.3721239
3: 10 0.5728534
4:  7 0.9082078
> Y[inrange(a, range$start, range$end, incbounds=FALSE)] # open interval
   a       val
1: 8 0.2655087
2: 3 0.3721239
3: 7 0.9082078
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("between", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("chmatch")
> ### * chmatch
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: chmatch
> ### Title: Faster match of character vectors
> ### Aliases: chmatch %chin% chorder chgroup
> ### Keywords: data
> 
> ### ** Examples
> 
> # Please type 'example(chmatch)' to run this and see timings on your machine
> 
> N = 1e5
> # N is set small here (1e5) to reduce runtime because every day CRAN runs and checks
> # all documentation examples in addition to the package's test suite.
> # The comments here apply when N has been changed to 1e8 and were run on 2018-05-13
> # with R 3.5.0 and data.table 1.11.2.
> 
> u = as.character(as.hexmode(1:10000))
> y = sample(u,N,replace=TRUE)
> x = sample(u)
>                                            #  With N=1e8 ...
> system.time(a <- match(x,y))               #  4.6s
   user  system elapsed 
  0.043   0.000   0.004 
> system.time(b <- chmatch(x,y))             #  1.8s
   user  system elapsed 
  0.023   0.000   0.001 
> identical(a,b)
[1] TRUE
> 
> system.time(a <- x %in% y)               #  4.5s
   user  system elapsed 
  0.041   0.000   0.003 
> system.time(b <- x %chin% y)             #  1.7s
   user  system elapsed 
  0.024   0.000   0.002 
> identical(a,b)
[1] TRUE
> 
> # Different example with more unique strings ...
> u = as.character(as.hexmode(1:(N/10)))
> y = sample(u,N,replace=TRUE)
> x = sample(u,N,replace=TRUE)
> system.time(a <- match(x,y))               # 46s
   user  system elapsed 
  0.070   0.001   0.006 
> system.time(b <- chmatch(x,y))             # 16s
   user  system elapsed 
  0.045   0.001   0.003 
> identical(a,b)
[1] TRUE
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("chmatch", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("copy")
> ### * copy
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: copy
> ### Title: Copy an entire object
> ### Aliases: copy
> ### Keywords: data
> 
> ### ** Examples
> 
> # Type 'example(copy)' to run these at prompt and browse output
> 
> DT = data.table(A=5:1,B=letters[5:1])
> DT2 = copy(DT)        # explicit copy() needed to copy a data.table
> setkey(DT2,B)         # now just changes DT2
> identical(DT,DT2)     # FALSE. DT and DT2 are now different tables
[1] FALSE
> 
> DT = data.table(A=5:1, B=letters[5:1])
> nm1 = names(DT)
> nm2 = copy(names(DT))
> DT[, C := 1L]
> identical(nm1, names(DT)) # TRUE, nm1 is also changed by reference
[1] TRUE
> identical(nm2, names(DT)) # FALSE, nm2 is a copy, different from names(DT)
[1] FALSE
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("copy", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("data.table-class")
> ### * data.table-class
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: data.table-class
> ### Title: S4 Definition for data.table
> ### Aliases: class:data.table data.table-class
> ### Keywords: classes methods
> 
> ### ** Examples
> 
> ## Used in inheritence.
> setClass('SuperDataTable', contains='data.table')
> 
> ## Used in a slot
> setClass('Something', representation(x='character', dt='data.table'))
> x <- new("Something", x='check', dt=data.table(a=1:10, b=11:20))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("data.table-class", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("data.table")
> ### * data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: data.table-package
> ### Title: Enhanced data.frame
> ### Aliases: data.table-package data.table Ops.data.table is.na.data.table
> ###   [.data.table
> ### Keywords: data
> 
> ### ** Examples
> 
> ## Not run: 
> ##D example(data.table)  # to run these examples at the prompt
> ## End(Not run)
> DF = data.frame(x=rep(c("b","a","c"),each=3), y=c(1,3,6), v=1:9)
> DT = data.table(x=rep(c("b","a","c"),each=3), y=c(1,3,6), v=1:9)
> DF
  x y v
1 b 1 1
2 b 3 2
3 b 6 3
4 a 1 4
5 a 3 5
6 a 6 6
7 c 1 7
8 c 3 8
9 c 6 9
> DT
   x y v
1: b 1 1
2: b 3 2
3: b 6 3
4: a 1 4
5: a 3 5
6: a 6 6
7: c 1 7
8: c 3 8
9: c 6 9
> identical(dim(DT), dim(DF))    # TRUE
[1] TRUE
> identical(DF$a, DT$a)          # TRUE
[1] TRUE
> is.list(DF)                    # TRUE
[1] TRUE
> is.list(DT)                    # TRUE
[1] TRUE
> 
> is.data.frame(DT)              # TRUE
[1] TRUE
> 
> tables()
   NAME NROW NCOL MB  COLS KEY
1:   DT    9    3  0 x,y,v    
Total: 0MB
> 
> # basic row subset operations
> DT[2]                          # 2nd row
   x y v
1: b 3 2
> DT[3:2]                        # 3rd and 2nd row
   x y v
1: b 6 3
2: b 3 2
> DT[order(x)]                   # no need for order(DT$x)
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
4: b 1 1
5: b 3 2
6: b 6 3
7: c 1 7
8: c 3 8
9: c 6 9
> DT[order(x), ]                 # same as above. The ',' is optional
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
4: b 1 1
5: b 3 2
6: b 6 3
7: c 1 7
8: c 3 8
9: c 6 9
> DT[y>2]                        # all rows where DT$y > 2
   x y v
1: b 3 2
2: b 6 3
3: a 3 5
4: a 6 6
5: c 3 8
6: c 6 9
> DT[y>2 & v>5]                  # compound logical expressions
   x y v
1: a 6 6
2: c 3 8
3: c 6 9
> DT[!2:4]                       # all rows other than 2:4
   x y v
1: b 1 1
2: a 3 5
3: a 6 6
4: c 1 7
5: c 3 8
6: c 6 9
> DT[-(2:4)]                     # same
   x y v
1: b 1 1
2: a 3 5
3: a 6 6
4: c 1 7
5: c 3 8
6: c 6 9
> 
> # select|compute columns data.table way
> DT[, v]                        # v column (as vector)
[1] 1 2 3 4 5 6 7 8 9
> DT[, list(v)]                  # v column (as data.table)
   v
1: 1
2: 2
3: 3
4: 4
5: 5
6: 6
7: 7
8: 8
9: 9
> DT[, .(v)]                     # same as above, .() is a shorthand alias to list()
   v
1: 1
2: 2
3: 3
4: 4
5: 5
6: 6
7: 7
8: 8
9: 9
> DT[, sum(v)]                   # sum of column v, returned as vector
[1] 45
> DT[, .(sum(v))]                # same, but return data.table (column autonamed V1)
   V1
1: 45
> DT[, .(sv=sum(v))]             # same, but column named "sv"
   sv
1: 45
> DT[, .(v, v*2)]                # return two column data.table, v and v*2
   v V2
1: 1  2
2: 2  4
3: 3  6
4: 4  8
5: 5 10
6: 6 12
7: 7 14
8: 8 16
9: 9 18
> 
> # subset rows and select|compute data.table way
> DT[2:3, sum(v)]                # sum(v) over rows 2 and 3, return vector
[1] 5
> DT[2:3, .(sum(v))]             # same, but return data.table with column V1
   V1
1:  5
> DT[2:3, .(sv=sum(v))]          # same, but return data.table with column sv
   sv
1:  5
> DT[2:5, cat(v, "\n")]          # just for j's side effect
2 3 4 5 
NULL
> 
> # select columns the data.frame way
> DT[, 2]                        # 2nd column, returns a data.table always
   y
1: 1
2: 3
3: 6
4: 1
5: 3
6: 6
7: 1
8: 3
9: 6
> colNum = 2                     # to refer vars in `j` from the outside of data use `..` prefix
> DT[, ..colNum]                 # same, equivalent to DT[, .SD, .SDcols=colNum]
   y
1: 1
2: 3
3: 6
4: 1
5: 3
6: 6
7: 1
8: 3
9: 6
> DT[["v"]]                      # same as DT[, v] but much faster
[1] 1 2 3 4 5 6 7 8 9
> 
> # grouping operations - j and by
> DT[, sum(v), by=x]             # ad hoc by, order of groups preserved in result
   x V1
1: b  6
2: a 15
3: c 24
> DT[, sum(v), keyby=x]          # same, but order the result on by cols
   x V1
1: a 15
2: b  6
3: c 24
> DT[, sum(v), by=x][order(x)]   # same but by chaining expressions together
   x V1
1: a 15
2: b  6
3: c 24
> 
> # fast ad hoc row subsets (subsets as joins)
> DT["a", on="x"]                # same as x == "a" but uses binary search (fast)
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> DT["a", on=.(x)]               # same, for convenience, no need to quote every column
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> DT[.("a"), on="x"]             # same
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> DT[x=="a"]                     # same, single "==" internally optimised to use binary search (fast)
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> DT[x!="b" | y!=3]              # not yet optimized, currently vector scan subset
   x y v
1: b 1 1
2: b 6 3
3: a 1 4
4: a 3 5
5: a 6 6
6: c 1 7
7: c 3 8
8: c 6 9
> DT[.("b", 3), on=c("x", "y")]  # join on columns x,y of DT; uses binary search (fast)
   x y v
1: b 3 2
> DT[.("b", 3), on=.(x, y)]      # same, but using on=.()
   x y v
1: b 3 2
> DT[.("b", 1:2), on=c("x", "y")]             # no match returns NA
   x y  v
1: b 1  1
2: b 2 NA
> DT[.("b", 1:2), on=.(x, y), nomatch=NULL]   # no match row is not returned
   x y v
1: b 1 1
> DT[.("b", 1:2), on=c("x", "y"), roll=Inf]   # locf, nomatch row gets rolled by previous row
   x y v
1: b 1 1
2: b 2 1
> DT[.("b", 1:2), on=.(x, y), roll=-Inf]      # nocb, nomatch row gets rolled by next row
   x y v
1: b 1 1
2: b 2 2
> DT["b", sum(v*y), on="x"]                   # on rows where DT$x=="b", calculate sum(v*y)
[1] 25
> 
> # all together now
> DT[x!="a", sum(v), by=x]                    # get sum(v) by "x" for each i != "a"
   x V1
1: b  6
2: c 24
> DT[!"a", sum(v), by=.EACHI, on="x"]         # same, but using subsets-as-joins
   x V1
1: b  6
2: c 24
> DT[c("b","c"), sum(v), by=.EACHI, on="x"]   # same
   x V1
1: b  6
2: c 24
> DT[c("b","c"), sum(v), by=.EACHI, on=.(x)]  # same, using on=.()
   x V1
1: b  6
2: c 24
> 
> # joins as subsets
> X = data.table(x=c("c","b"), v=8:7, foo=c(4,2))
> X
   x v foo
1: c 8   4
2: b 7   2
> 
> DT[X, on="x"]                         # right join
   x y v i.v foo
1: c 1 7   8   4
2: c 3 8   8   4
3: c 6 9   8   4
4: b 1 1   7   2
5: b 3 2   7   2
6: b 6 3   7   2
> X[DT, on="x"]                         # left join
   x  v foo y i.v
1: b  7   2 1   1
2: b  7   2 3   2
3: b  7   2 6   3
4: a NA  NA 1   4
5: a NA  NA 3   5
6: a NA  NA 6   6
7: c  8   4 1   7
8: c  8   4 3   8
9: c  8   4 6   9
> DT[X, on="x", nomatch=NULL]           # inner join
   x y v i.v foo
1: c 1 7   8   4
2: c 3 8   8   4
3: c 6 9   8   4
4: b 1 1   7   2
5: b 3 2   7   2
6: b 6 3   7   2
> DT[!X, on="x"]                        # not join
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> DT[X, on=c(y="v")]                    # join using column "y" of DT with column "v" of X
      x y  v i.x foo
1: <NA> 8 NA   c   4
2: <NA> 7 NA   b   2
> DT[X, on="y==v"]                      # same as above (v1.9.8+)
      x y  v i.x foo
1: <NA> 8 NA   c   4
2: <NA> 7 NA   b   2
> 
> DT[X, on=.(y<=foo)]                   # NEW non-equi join (v1.9.8+)
   x y v i.x i.v
1: b 4 1   c   8
2: b 4 2   c   8
3: a 4 4   c   8
4: a 4 5   c   8
5: c 4 7   c   8
6: c 4 8   c   8
7: b 2 1   b   7
8: a 2 4   b   7
9: c 2 7   b   7
> DT[X, on="y<=foo"]                    # same as above
   x y v i.x i.v
1: b 4 1   c   8
2: b 4 2   c   8
3: a 4 4   c   8
4: a 4 5   c   8
5: c 4 7   c   8
6: c 4 8   c   8
7: b 2 1   b   7
8: a 2 4   b   7
9: c 2 7   b   7
> DT[X, on=c("y<=foo")]                 # same as above
   x y v i.x i.v
1: b 4 1   c   8
2: b 4 2   c   8
3: a 4 4   c   8
4: a 4 5   c   8
5: c 4 7   c   8
6: c 4 8   c   8
7: b 2 1   b   7
8: a 2 4   b   7
9: c 2 7   b   7
> DT[X, on=.(y>=foo)]                   # NEW non-equi join (v1.9.8+)
   x y v i.x i.v
1: b 4 3   c   8
2: a 4 6   c   8
3: c 4 9   c   8
4: b 2 2   b   7
5: b 2 3   b   7
6: a 2 5   b   7
7: a 2 6   b   7
8: c 2 8   b   7
9: c 2 9   b   7
> DT[X, on=.(x, y<=foo)]                # NEW non-equi join (v1.9.8+)
   x y v i.v
1: c 4 7   8
2: c 4 8   8
3: b 2 1   7
> DT[X, .(x,y,x.y,v), on=.(x, y>=foo)]  # Select x's join columns as well
   x y x.y v
1: c 4   6 9
2: b 2   3 2
3: b 2   6 3
> 
> DT[X, on="x", mult="first"]           # first row of each group
   x y v i.v foo
1: c 1 7   8   4
2: b 1 1   7   2
> DT[X, on="x", mult="last"]            # last row of each group
   x y v i.v foo
1: c 6 9   8   4
2: b 6 3   7   2
> DT[X, sum(v), by=.EACHI, on="x"]      # join and eval j for each row in i
   x V1
1: c 24
2: b  6
> DT[X, sum(v)*foo, by=.EACHI, on="x"]  # join inherited scope
   x V1
1: c 96
2: b 12
> DT[X, sum(v)*i.v, by=.EACHI, on="x"]  # 'i,v' refers to X's v column
   x  V1
1: c 192
2: b  42
> DT[X, on=.(x, v>=v), sum(y)*foo, by=.EACHI] # NEW non-equi join with by=.EACHI (v1.9.8+)
   x v V1
1: c 8 36
2: b 7 NA
> 
> # setting keys
> kDT = copy(DT)                        # (deep) copy DT to kDT to work with it.
> setkey(kDT,x)                         # set a 1-column key. No quotes, for convenience.
> setkeyv(kDT,"x")                      # same (v in setkeyv stands for vector)
> v="x"
> setkeyv(kDT,v)                        # same
> # key(kDT)<-"x"                       # copies whole table, please use set* functions instead
> haskey(kDT)                           # TRUE
[1] TRUE
> key(kDT)                              # "x"
[1] "x"
> 
> # fast *keyed* subsets
> kDT["a"]                              # subset-as-join on *key* column 'x'
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> kDT["a", on="x"]                      # same, being explicit using 'on=' (preferred)
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> 
> # all together
> kDT[!"a", sum(v), by=.EACHI]          # get sum(v) for each i != "a"
   x V1
1: b  6
2: c 24
> 
> # multi-column key
> setkey(kDT,x,y)                       # 2-column key
> setkeyv(kDT,c("x","y"))               # same
> 
> # fast *keyed* subsets on multi-column key
> kDT["a"]                              # join to 1st column of key
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> kDT["a", on="x"]                      # on= is optional, but is preferred
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> kDT[.("a")]                           # same, .() is an alias for list()
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> kDT[list("a")]                        # same
   x y v
1: a 1 4
2: a 3 5
3: a 6 6
> kDT[.("a", 3)]                        # join to 2 columns
   x y v
1: a 3 5
> kDT[.("a", 3:6)]                      # join 4 rows (2 missing)
   x y  v
1: a 3  5
2: a 4 NA
3: a 5 NA
4: a 6  6
> kDT[.("a", 3:6), nomatch=NULL]        # remove missing
   x y v
1: a 3 5
2: a 6 6
> kDT[.("a", 3:6), roll=TRUE]           # locf rolling join
   x y v
1: a 3 5
2: a 4 5
3: a 5 5
4: a 6 6
> kDT[.("a", 3:6), roll=Inf]            # same as above
   x y v
1: a 3 5
2: a 4 5
3: a 5 5
4: a 6 6
> kDT[.("a", 3:6), roll=-Inf]           # nocb rolling join
   x y v
1: a 3 5
2: a 4 6
3: a 5 6
4: a 6 6
> kDT[!.("a")]                          # not join
   x y v
1: b 1 1
2: b 3 2
3: b 6 3
4: c 1 7
5: c 3 8
6: c 6 9
> kDT[!"a"]                             # same
   x y v
1: b 1 1
2: b 3 2
3: b 6 3
4: c 1 7
5: c 3 8
6: c 6 9
> 
> # more on special symbols, see also ?"special-symbols"
> DT[.N]                                  # last row
   x y v
1: c 6 9
> DT[, .N]                                # total number of rows in DT
[1] 9
> DT[, .N, by=x]                          # number of rows in each group
   x N
1: b 3
2: a 3
3: c 3
> DT[, .SD, .SDcols=x:y]                  # select columns 'x' through 'y'
   x y
1: b 1
2: b 3
3: b 6
4: a 1
5: a 3
6: a 6
7: c 1
8: c 3
9: c 6
> DT[ , .SD, .SDcols = !x:y]              # drop columns 'x' through 'y'
   v
1: 1
2: 2
3: 3
4: 4
5: 5
6: 6
7: 7
8: 8
9: 9
> DT[ , .SD, .SDcols = patterns('^[xv]')] # select columns matching '^x' or '^v'
   x v
1: b 1
2: b 2
3: b 3
4: a 4
5: a 5
6: a 6
7: c 7
8: c 8
9: c 9
> DT[, .SD[1]]                            # first row of all columns
   x y v
1: b 1 1
> DT[, .SD[1], by=x]                      # first row of 'y' and 'v' for each group in 'x'
   x y v
1: b 1 1
2: a 1 4
3: c 1 7
> DT[, c(.N, lapply(.SD, sum)), by=x]     # get rows *and* sum columns 'v' and 'y' by group
   x N  y  v
1: b 3 10  6
2: a 3 10 15
3: c 3 10 24
> DT[, .I[1], by=x]                       # row number in DT corresponding to each group
   x V1
1: b  1
2: a  4
3: c  7
> DT[, grp := .GRP, by=x]                 # add a group counter column
> X[, DT[.BY, y, on="x"], by=x]           # join within each group
   x V1
1: c  1
2: c  3
3: c  6
4: b  1
5: b  3
6: b  6
> 
> # add/update/delete by reference (see ?assign)
> print(DT[, z:=42L])                   # add new column by reference
> print(DT[, z:=NULL])                  # remove column by reference
> print(DT["a", v:=42L, on="x"])        # subassign to existing v column by reference
> print(DT["b", v2:=84L, on="x"])       # subassign to new column by reference (NA padded)
> 
> DT[, m:=mean(v), by=x][]              # add new column by reference by group
   x y  v grp v2  m
1: b 1  1   1 84  2
2: b 3  2   1 84  2
3: b 6  3   1 84  2
4: a 1 42   2 NA 42
5: a 3 42   2 NA 42
6: a 6 42   2 NA 42
7: c 1  7   3 NA  8
8: c 3  8   3 NA  8
9: c 6  9   3 NA  8
>                                       # NB: postfix [] is shortcut to print()
> # advanced usage
> DT = data.table(x=rep(c("b","a","c"),each=3), v=c(1,1,1,2,2,1,1,2,2), y=c(1,3,6), a=1:9, b=9:1)
> 
> DT[, sum(v), by=.(y%%2)]              # expressions in by
   y V1
1: 1  9
2: 0  4
> DT[, sum(v), by=.(bool = y%%2)]       # same, using a named list to change by column name
   bool V1
1:    1  9
2:    0  4
> DT[, .SD[2], by=x]                    # get 2nd row of each group
   x v y a b
1: b 1 3 2 8
2: a 2 3 5 5
3: c 2 3 8 2
> DT[, tail(.SD,2), by=x]               # last 2 rows of each group
   x v y a b
1: b 1 3 2 8
2: b 1 6 3 7
3: a 2 3 5 5
4: a 1 6 6 4
5: c 2 3 8 2
6: c 2 6 9 1
> DT[, lapply(.SD, sum), by=x]          # sum of all (other) columns for each group
   x v  y  a  b
1: b 3 10  6 24
2: a 5 10 15 15
3: c 5 10 24  6
> DT[, .SD[which.min(v)], by=x]         # nested query by group
   x v y a b
1: b 1 1 1 9
2: a 1 6 6 4
3: c 1 1 7 3
> 
> DT[, list(MySum=sum(v),
+           MyMin=min(v),
+           MyMax=max(v)),
+     by=.(x, y%%2)]                    # by 2 expressions
   x y MySum MyMin MyMax
1: b 1     2     1     1
2: b 0     1     1     1
3: a 1     4     2     2
4: a 0     1     1     1
5: c 1     3     1     2
6: c 0     2     2     2
> 
> DT[, .(a = .(a), b = .(b)), by=x]     # list columns
   x     a     b
1: b 1,2,3 9,8,7
2: a 4,5,6 6,5,4
3: c 7,8,9 3,2,1
> DT[, .(seq = min(a):max(b)), by=x]    # j is not limited to just aggregations
    x seq
 1: b   1
 2: b   2
 3: b   3
 4: b   4
 5: b   5
 6: b   6
 7: b   7
 8: b   8
 9: b   9
10: a   4
11: a   5
12: a   6
13: c   7
14: c   6
15: c   5
16: c   4
17: c   3
> DT[, sum(v), by=x][V1<20]             # compound query
   x V1
1: b  3
2: a  5
3: c  5
> DT[, sum(v), by=x][order(-V1)]        # ordering results
   x V1
1: a  5
2: c  5
3: b  3
> DT[, c(.N, lapply(.SD,sum)), by=x]    # get number of observations and sum per group
   x N v  y  a  b
1: b 3 3 10  6 24
2: a 3 5 10 15 15
3: c 3 5 10 24  6
> DT[, {tmp <- mean(y);
+       .(a = a-tmp, b = b-tmp)
+       }, by=x]                        # anonymous lambda in 'j', j accepts any valid
   x          a          b
1: b -2.3333333  5.6666667
2: b -1.3333333  4.6666667
3: b -0.3333333  3.6666667
4: a  0.6666667  2.6666667
5: a  1.6666667  1.6666667
6: a  2.6666667  0.6666667
7: c  3.6666667 -0.3333333
8: c  4.6666667 -1.3333333
9: c  5.6666667 -2.3333333
>                                       # expression. TO REMEMBER: every element of
>                                       # the list becomes a column in result.
> pdf("new.pdf")
> DT[, plot(a,b), by=x]                 # can also plot in 'j'
Empty data.table (0 rows) of 1 col: x
> dev.off()
pdf 
  2 
> 
> # using rleid, get max(y) and min of all cols in .SDcols for each consecutive run of 'v'
> DT[, c(.(y=max(y)), lapply(.SD, min)), by=rleid(v), .SDcols=v:b]
   rleid y v y a b
1:     1 6 1 1 1 7
2:     2 3 2 1 4 5
3:     3 6 1 1 6 3
4:     4 6 2 3 8 1
> 
> # Support guide and links:
> # https://github.com/Rdatatable/data.table/wiki/Support
> 
> ## Not run: 
> ##D if (interactive()) {
> ##D   vignette("datatable-intro")
> ##D   vignette("datatable-reference-semantics")
> ##D   vignette("datatable-keys-fast-subset")
> ##D   vignette("datatable-secondary-indices-and-auto-indexing")
> ##D   vignette("datatable-reshape")
> ##D   vignette("datatable-faq")
> ##D 
> ##D   test.data.table()          # over 6,000 low level tests
> ##D 
> ##D   # keep up to date with latest stable version on CRAN
> ##D   update.packages()
> ##D 
> ##D   # get the latest devel version
> ##D   update.dev.pkg()
> ##D   # compiled devel binary for Windows available -- no Rtools needed
> ##D   update.dev.pkg(repo="https://Rdatatable.github.io/data.table")
> ##D   # read more at:
> ##D   # https://github.com/Rdatatable/data.table/wiki/Installation
> ##D }
> ## End(Not run)
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("datatable-optimize")
> ### * datatable-optimize
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: datatable.optimize
> ### Title: Optimisations in data.table
> ### Aliases: datatable-optimize datatable.optimize data.table-optimize
> ###   data.table.optimize gforce GForce autoindex autoindexing auto-index
> ###   auto-indexing rounding
> ### Keywords: data
> 
> ### ** Examples
> 
> ## Not run: 
> ##D # Generate a big data.table with a relatively many columns
> ##D set.seed(1L)
> ##D DT = lapply(1:20, function(x) sample(c(-100:100), 5e6L, TRUE))
> ##D setDT(DT)[, id := sample(1e5, 5e6, TRUE)]
> ##D print(object.size(DT), units="Mb") # 400MB, not huge, but will do
> ##D 
> ##D # 'order' optimisation
> ##D options(datatable.optimize = 1L) # optimisation 'on'
> ##D system.time(ans1 <- DT[order(id)])
> ##D options(datatable.optimize = 0L) # optimisation 'off'
> ##D system.time(ans2 <- DT[order(id)])
> ##D identical(ans1, ans2)
> ##D 
> ##D # optimisation of 'lapply(.SD, fun)'
> ##D options(datatable.optimize = 1L) # optimisation 'on'
> ##D system.time(ans1 <- DT[, lapply(.SD, min), by=id])
> ##D options(datatable.optimize = 0L) # optimisation 'off'
> ##D system.time(ans2 <- DT[, lapply(.SD, min), by=id])
> ##D identical(ans1, ans2)
> ##D 
> ##D # optimisation of 'mean'
> ##D options(datatable.optimize = 1L) # optimisation 'on'
> ##D system.time(ans1 <- DT[, lapply(.SD, mean), by=id])
> ##D system.time(ans2 <- DT[, lapply(.SD, base::mean), by=id])
> ##D identical(ans1, ans2)
> ##D 
> ##D # optimisation of 'c(.N, lapply(.SD, ))'
> ##D options(datatable.optimize = 1L) # optimisation 'on'
> ##D system.time(ans1 <- DT[, c(.N, lapply(.SD, min)), by=id])
> ##D options(datatable.optimize = 0L) # optimisation 'off'
> ##D system.time(ans2 <- DT[, c(N=.N, lapply(.SD, min)), by=id])
> ##D identical(ans1, ans2)
> ##D 
> ##D # GForce
> ##D options(datatable.optimize = 2L) # optimisation 'on'
> ##D system.time(ans1 <- DT[, lapply(.SD, median), by=id])
> ##D system.time(ans2 <- DT[, lapply(.SD, function(x) as.numeric(stats::median(x))), by=id])
> ##D identical(ans1, ans2)
> ##D 
> ##D # optimized subsets
> ##D options(datatable.optimize = 2L)
> ##D system.time(ans1 <- DT[id == 100L]) # vector scan
> ##D system.time(ans2 <- DT[id == 100L]) # vector scan
> ##D system.time(DT[id %in% 100:500])    # vector scan
> ##D 
> ##D options(datatable.optimize = 3L)
> ##D system.time(ans1 <- DT[id == 100L]) # index + binary search subset
> ##D system.time(ans2 <- DT[id == 100L]) # only binary search subset
> ##D system.time(DT[id %in% 100:500])    # only binary search subset again
> ##D 
> ## End(Not run)
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("datatable-optimize", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("dcast.data.table")
> ### * dcast.data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: dcast.data.table
> ### Title: Fast dcast for data.table
> ### Aliases: dcast.data.table dcast
> ### Keywords: data
> 
> ### ** Examples
> 
> require(data.table)
> names(ChickWeight) <- tolower(names(ChickWeight))
> DT <- melt(as.data.table(ChickWeight), id=2:4) # calls melt.data.table
> 
> # dcast is a S3 method in data.table from v1.9.6
> dcast(DT, time ~ variable, fun=mean)
    time    weight
 1:    0  41.06000
 2:    2  49.22000
 3:    4  59.95918
 4:    6  74.30612
 5:    8  91.24490
 6:   10 107.83673
 7:   12 129.24490
 8:   14 143.81250
 9:   16 168.08511
10:   18 190.19149
11:   20 209.71739
12:   21 218.68889
> dcast(DT, diet ~ variable, fun=mean)
   diet   weight
1:    1 102.6455
2:    2 122.6167
3:    3 142.9500
4:    4 135.2627
> dcast(DT, diet+chick ~ time, drop=FALSE)
     diet chick  0  2  4  6   8  10  12  14  16  18  20  21
  1:    1    18 39 35 NA NA  NA  NA  NA  NA  NA  NA  NA  NA
  2:    1    16 41 45 49 51  57  51  54  NA  NA  NA  NA  NA
  3:    1    15 41 49 56 64  68  68  67  68  NA  NA  NA  NA
  4:    1    13 41 48 53 60  65  67  71  70  71  81  91  96
  5:    1     9 42 51 59 68  85  96  90  92  93 100 100  98
 ---                                                       
196:    4    49 40 53 64 85 108 128 152 166 184 203 233 237
197:    4    46 40 52 62 82 101 120 144 156 173 210 231 238
198:    4    50 41 54 67 84 105 122 155 175 205 234 264 264
199:    4    42 42 49 63 84 103 126 160 174 204 234 269 281
200:    4    48 39 50 62 80 104 125 154 170 222 261 303 322
> dcast(DT, diet+chick ~ time, drop=FALSE, fill=0)
     diet chick  0  2  4  6   8  10  12  14  16  18  20  21
  1:    1    18 39 35  0  0   0   0   0   0   0   0   0   0
  2:    1    16 41 45 49 51  57  51  54   0   0   0   0   0
  3:    1    15 41 49 56 64  68  68  67  68   0   0   0   0
  4:    1    13 41 48 53 60  65  67  71  70  71  81  91  96
  5:    1     9 42 51 59 68  85  96  90  92  93 100 100  98
 ---                                                       
196:    4    49 40 53 64 85 108 128 152 166 184 203 233 237
197:    4    46 40 52 62 82 101 120 144 156 173 210 231 238
198:    4    50 41 54 67 84 105 122 155 175 205 234 264 264
199:    4    42 42 49 63 84 103 126 160 174 204 234 269 281
200:    4    48 39 50 62 80 104 125 154 170 222 261 303 322
> 
> # using subset
> dcast(DT, chick ~ time, fun=mean, subset=.(time < 10 & chick < 20))
   chick  0  2   4   6   8
1:    18 39 35 NaN NaN NaN
2:    16 41 45  49  51  57
3:    15 41 49  56  64  68
4:    13 41 48  53  60  65
5:     9 42 51  59  68  85
> 
> # drop argument, #1512
> DT <- data.table(v1 = c(1.1, 1.1, 1.1, 2.2, 2.2, 2.2),
+                  v2 = factor(c(1L, 1L, 1L, 3L, 3L, 3L), levels=1:3),
+                  v3 = factor(c(2L, 3L, 5L, 1L, 2L, 6L), levels=1:6),
+                  v4 = c(3L, 2L, 2L, 5L, 4L, 3L))
> # drop=TRUE
> dcast(DT, v1 + v2 ~ v3)                      # default is drop=TRUE
Using 'v4' as value column. Use 'value.var' to override
    v1 v2  1 2  3  5  6
1: 1.1  1 NA 3  2  2 NA
2: 2.2  3  5 4 NA NA  3
> dcast(DT, v1 + v2 ~ v3, drop=FALSE)          # all missing combinations of both LHS and RHS
Using 'v4' as value column. Use 'value.var' to override
    v1 v2  1  2  3  4  5  6
1: 1.1  1 NA  3  2 NA  2 NA
2: 1.1  2 NA NA NA NA NA NA
3: 1.1  3 NA NA NA NA NA NA
4: 2.2  1 NA NA NA NA NA NA
5: 2.2  2 NA NA NA NA NA NA
6: 2.2  3  5  4 NA NA NA  3
> dcast(DT, v1 + v2 ~ v3, drop=c(FALSE, TRUE)) # all missing combinations of only LHS
Using 'v4' as value column. Use 'value.var' to override
    v1 v2  1  2  3  5  6
1: 1.1  1 NA  3  2  2 NA
2: 1.1  2 NA NA NA NA NA
3: 1.1  3 NA NA NA NA NA
4: 2.2  1 NA NA NA NA NA
5: 2.2  2 NA NA NA NA NA
6: 2.2  3  5  4 NA NA  3
> dcast(DT, v1 + v2 ~ v3, drop=c(TRUE, FALSE)) # all missing combinations of only RHS
Using 'v4' as value column. Use 'value.var' to override
    v1 v2  1 2  3  4  5  6
1: 1.1  1 NA 3  2 NA  2 NA
2: 2.2  3  5 4 NA NA NA  3
> 
> # using . and ...
> DT <- data.table(v1 = rep(1:2, each = 6),
+                  v2 = rep(rep(1:3, 2), each = 2),
+                  v3 = rep(1:2, 6),
+                  v4 = rnorm(6))
> dcast(DT, ... ~ v3, value.var = "v4") #same as v1 + v2 ~ v3, value.var = "v4"
   v1 v2          1          2
1:  1  1 -0.6264538  0.1836433
2:  1  2 -0.8356286  1.5952808
3:  1  3  0.3295078 -0.8204684
4:  2  1 -0.6264538  0.1836433
5:  2  2 -0.8356286  1.5952808
6:  2  3  0.3295078 -0.8204684
> dcast(DT, v1 + v2 + v3 ~ ., value.var = "v4")
    v1 v2 v3          .
 1:  1  1  1 -0.6264538
 2:  1  1  2  0.1836433
 3:  1  2  1 -0.8356286
 4:  1  2  2  1.5952808
 5:  1  3  1  0.3295078
 6:  1  3  2 -0.8204684
 7:  2  1  1 -0.6264538
 8:  2  1  2  0.1836433
 9:  2  2  1 -0.8356286
10:  2  2  2  1.5952808
11:  2  3  1  0.3295078
12:  2  3  2 -0.8204684
> 
> ## for each combination of (v1, v2), add up all values of v4
> dcast(DT, v1 + v2 ~ ., value.var = "v4", fun.aggregate = sum)
   v1 v2          .
1:  1  1 -0.4428105
2:  1  2  0.7596522
3:  1  3 -0.4909606
4:  2  1 -0.4428105
5:  2  2  0.7596522
6:  2  3 -0.4909606
> 
> ## Not run: 
> ##D # benchmark against reshape2's dcast, minimum of 3 runs
> ##D set.seed(45)
> ##D DT <- data.table(aa=sample(1e4, 1e6, TRUE),
> ##D       bb=sample(1e3, 1e6, TRUE),
> ##D       cc = sample(letters, 1e6, TRUE), dd=runif(1e6))
> ##D system.time(dcast(DT, aa ~ cc, fun=sum)) # 0.12 seconds
> ##D system.time(dcast(DT, bb ~ cc, fun=mean)) # 0.04 seconds
> ##D # reshape2::dcast takes 31 seconds
> ##D system.time(dcast(DT, aa + bb ~ cc, fun=sum)) # 1.2 seconds
> ## End(Not run)
> 
> # NEW FEATURE - multiple value.var and multiple fun.aggregate
> DT = data.table(x=sample(5,20,TRUE), y=sample(2,20,TRUE),
+                 z=sample(letters[1:2], 20,TRUE), d1 = runif(20), d2=1L)
> # multiple value.var
> dcast(DT, x + y ~ z, fun=sum, value.var=c("d1","d2"))
    x y      d1_a       d1_b d2_a d2_b
 1: 1 1 0.7111212 0.00000000    1    0
 2: 1 2 0.3253522 0.00000000    1    0
 3: 2 1 0.3337749 0.12169192    1    1
 4: 2 2 0.9152069 1.67771223    2    3
 5: 3 1 0.2396294 0.00000000    1    0
 6: 3 2 0.8921983 0.05893438    1    1
 7: 4 1 1.3073015 0.00000000    2    0
 8: 4 2 1.7406851 0.00000000    3    0
 9: 5 1 0.0000000 0.38998954    0    1
10: 5 2 0.2454885 0.43465948    1    1
> # multiple fun.aggregate
> dcast(DT, x + y ~ z, fun=list(sum, mean), value.var="d1")
    x y  d1_sum_a   d1_sum_b d1_mean_a  d1_mean_b
 1: 1 1 0.7111212 0.00000000 0.7111212        NaN
 2: 1 2 0.3253522 0.00000000 0.3253522        NaN
 3: 2 1 0.3337749 0.12169192 0.3337749 0.12169192
 4: 2 2 0.9152069 1.67771223 0.4576035 0.55923741
 5: 3 1 0.2396294 0.00000000 0.2396294        NaN
 6: 3 2 0.8921983 0.05893438 0.8921983 0.05893438
 7: 4 1 1.3073015 0.00000000 0.6536507        NaN
 8: 4 2 1.7406851 0.00000000 0.5802284        NaN
 9: 5 1 0.0000000 0.38998954       NaN 0.38998954
10: 5 2 0.2454885 0.43465948 0.2454885 0.43465948
> # multiple fun.agg and value.var (all combinations)
> dcast(DT, x + y ~ z, fun=list(sum, mean), value.var=c("d1", "d2"))
    x y  d1_sum_a   d1_sum_b d2_sum_a d2_sum_b d1_mean_a  d1_mean_b d2_mean_a
 1: 1 1 0.7111212 0.00000000        1        0 0.7111212        NaN         1
 2: 1 2 0.3253522 0.00000000        1        0 0.3253522        NaN         1
 3: 2 1 0.3337749 0.12169192        1        1 0.3337749 0.12169192         1
 4: 2 2 0.9152069 1.67771223        2        3 0.4576035 0.55923741         1
 5: 3 1 0.2396294 0.00000000        1        0 0.2396294        NaN         1
 6: 3 2 0.8921983 0.05893438        1        1 0.8921983 0.05893438         1
 7: 4 1 1.3073015 0.00000000        2        0 0.6536507        NaN         1
 8: 4 2 1.7406851 0.00000000        3        0 0.5802284        NaN         1
 9: 5 1 0.0000000 0.38998954        0        1       NaN 0.38998954       NaN
10: 5 2 0.2454885 0.43465948        1        1 0.2454885 0.43465948         1
    d2_mean_b
 1:       NaN
 2:       NaN
 3:         1
 4:         1
 5:       NaN
 6:         1
 7:       NaN
 8:       NaN
 9:         1
10:         1
> # multiple fun.agg and value.var (one-to-one)
> dcast(DT, x + y ~ z, fun=list(sum, mean), value.var=list("d1", "d2"))
    x y  d1_sum_a   d1_sum_b d2_mean_a d2_mean_b
 1: 1 1 0.7111212 0.00000000         1       NaN
 2: 1 2 0.3253522 0.00000000         1       NaN
 3: 2 1 0.3337749 0.12169192         1         1
 4: 2 2 0.9152069 1.67771223         1         1
 5: 3 1 0.2396294 0.00000000         1       NaN
 6: 3 2 0.8921983 0.05893438         1         1
 7: 4 1 1.3073015 0.00000000         1       NaN
 8: 4 2 1.7406851 0.00000000         1       NaN
 9: 5 1 0.0000000 0.38998954       NaN         1
10: 5 2 0.2454885 0.43465948         1         1
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("dcast.data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("duplicated")
> ### * duplicated
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: duplicated
> ### Title: Determine Duplicate Rows
> ### Aliases: duplicated duplicated.data.table unique unique.data.table
> ###   anyDuplicated anyDuplicated.data.table uniqueN
> ### Keywords: data
> 
> ### ** Examples
> 
> DT <- data.table(A = rep(1:3, each=4), B = rep(1:4, each=3),
+                   C = rep(1:2, 6), key = "A,B")
> duplicated(DT)
 [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
> unique(DT)
    A B C
 1: 1 1 1
 2: 1 1 2
 3: 1 2 2
 4: 2 2 1
 5: 2 2 2
 6: 2 3 1
 7: 2 3 2
 8: 3 3 1
 9: 3 4 2
10: 3 4 1
> 
> duplicated(DT, by="B")
 [1] FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE
> unique(DT, by="B")
   A B C
1: 1 1 1
2: 1 2 2
3: 2 3 1
4: 3 4 2
> 
> duplicated(DT, by=c("A", "C"))
 [1] FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE FALSE FALSE  TRUE  TRUE
> unique(DT, by=c("A", "C"))
   A B C
1: 1 1 1
2: 1 1 2
3: 2 2 1
4: 2 2 2
5: 3 3 1
6: 3 4 2
> 
> DT = data.table(a=c(2L,1L,2L), b=c(1L,2L,1L))   # no key
> unique(DT)                   # rows 1 and 2 (row 3 is a duplicate of row 1)
   a b
1: 2 1
2: 1 2
> 
> DT = data.table(a=c(3.142, 4.2, 4.2, 3.142, 1.223, 1.223), b=rep(1,6))
> unique(DT)                   # rows 1,2 and 5
       a b
1: 3.142 1
2: 4.200 1
3: 1.223 1
> 
> DT = data.table(a=tan(pi*(1/4 + 1:10)), b=rep(1,10))   # example from ?all.equal
> length(unique(DT$a))         # 10 strictly unique floating point values
[1] 5
> all.equal(DT$a,rep(1,10))    # TRUE, all within tolerance of 1.0
[1] TRUE
> DT[,which.min(a)]            # row 10, the strictly smallest floating point value
[1] 10
> identical(unique(DT),DT[1])  # TRUE, stable within tolerance
[1] FALSE
> identical(unique(DT),DT[10]) # FALSE
[1] FALSE
> 
> # fromLast=TRUE
> DT <- data.table(A = rep(1:3, each=4), B = rep(1:4, each=3),
+                  C = rep(1:2, 6), key = "A,B")
> duplicated(DT, by="B", fromLast=TRUE)
 [1]  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE  TRUE  TRUE FALSE
> unique(DT, by="B", fromLast=TRUE)
   A B C
1: 1 1 1
2: 2 2 2
3: 3 3 1
4: 3 4 2
> 
> # anyDuplicated
> anyDuplicated(DT, by=c("A", "B"))    # 3L
[1] 2
> any(duplicated(DT, by=c("A", "B")))  # TRUE
[1] TRUE
> 
> # uniqueN, unique rows on key columns
> uniqueN(DT, by = key(DT))
[1] 6
> # uniqueN, unique rows on all columns
> uniqueN(DT)
[1] 10
> # uniqueN while grouped by "A"
> DT[, .(uN=uniqueN(.SD)), by=A]
   A uN
1: 1  3
2: 2  4
3: 3  3
> 
> # uniqueN's na.rm=TRUE
> x = sample(c(NA, NaN, runif(3)), 10, TRUE)
> uniqueN(x, na.rm = FALSE) # 5, default
[1] 4
> uniqueN(x, na.rm=TRUE) # 3
[1] 2
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("duplicated", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("first")
> ### * first
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: first
> ### Title: First item of an object
> ### Aliases: first
> ### Keywords: data
> 
> ### ** Examples
> 
> first(1:5) # [1] 1
[1] 1
> x = data.table(x=1:5, y=6:10)
> first(x) # same as x[1]
   x y
1: 1 6
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("first", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("foverlaps")
> ### * foverlaps
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: foverlaps
> ### Title: Fast overlap joins
> ### Aliases: foverlaps
> ### Keywords: data
> 
> ### ** Examples
> 
> require(data.table)
> ## simple example:
> x = data.table(start=c(5,31,22,16), end=c(8,50,25,18), val2 = 7:10)
> y = data.table(start=c(10, 20, 30), end=c(15, 35, 45), val1 = 1:3)
> setkey(y, start, end)
> foverlaps(x, y, type="any", which=TRUE) ## return overlap indices
   xid yid
1:   1  NA
2:   2   2
3:   2   3
4:   3   2
5:   4  NA
> foverlaps(x, y, type="any") ## return overlap join
   start end val1 i.start i.end val2
1:    NA  NA   NA       5     8    7
2:    20  35    2      31    50    8
3:    30  45    3      31    50    8
4:    20  35    2      22    25    9
5:    NA  NA   NA      16    18   10
> foverlaps(x, y, type="any", mult="first") ## returns only first match
   start end val1 i.start i.end val2
1:    NA  NA   NA       5     8    7
2:    20  35    2      31    50    8
3:    20  35    2      22    25    9
4:    NA  NA   NA      16    18   10
> foverlaps(x, y, type="within") ## matches iff 'x' is within 'y'
   start end val1 i.start i.end val2
1:    NA  NA   NA       5     8    7
2:    NA  NA   NA      31    50    8
3:    20  35    2      22    25    9
4:    NA  NA   NA      16    18   10
> 
> ## with extra identifiers (ex: in genomics)
> x = data.table(chr=c("Chr1", "Chr1", "Chr2", "Chr2", "Chr2"),
+                start=c(5,10, 1, 25, 50), end=c(11,20,4,52,60))
> y = data.table(chr=c("Chr1", "Chr1", "Chr2"), start=c(1, 15,1),
+                end=c(4, 18, 55), geneid=letters[1:3])
> setkey(y, chr, start, end)
> foverlaps(x, y, type="any", which=TRUE)
   xid yid
1:   1  NA
2:   2   2
3:   3   3
4:   4   3
5:   5   3
> foverlaps(x, y, type="any")
    chr start end geneid i.start i.end
1: Chr1    NA  NA   <NA>       5    11
2: Chr1    15  18      b      10    20
3: Chr2     1  55      c       1     4
4: Chr2     1  55      c      25    52
5: Chr2     1  55      c      50    60
> foverlaps(x, y, type="any", nomatch=NULL)
    chr start end geneid i.start i.end
1: Chr1    15  18      b      10    20
2: Chr2     1  55      c       1     4
3: Chr2     1  55      c      25    52
4: Chr2     1  55      c      50    60
> foverlaps(x, y, type="within", which=TRUE)
   xid yid
1:   1  NA
2:   2  NA
3:   3   3
4:   4   3
5:   5  NA
> foverlaps(x, y, type="within")
    chr start end geneid i.start i.end
1: Chr1    NA  NA   <NA>       5    11
2: Chr1    NA  NA   <NA>      10    20
3: Chr2     1  55      c       1     4
4: Chr2     1  55      c      25    52
5: Chr2    NA  NA   <NA>      50    60
> foverlaps(x, y, type="start")
    chr start end geneid i.start i.end
1: Chr1    NA  NA   <NA>       5    11
2: Chr1    NA  NA   <NA>      10    20
3: Chr2     1  55      c       1     4
4: Chr2    NA  NA   <NA>      25    52
5: Chr2    NA  NA   <NA>      50    60
> 
> ## x and y have different column names - specify by.x
> x = data.table(seq=c("Chr1", "Chr1", "Chr2", "Chr2", "Chr2"),
+                start=c(5,10, 1, 25, 50), end=c(11,20,4,52,60))
> y = data.table(chr=c("Chr1", "Chr1", "Chr2"), start=c(1, 15,1),
+                end=c(4, 18, 55), geneid=letters[1:3])
> setkey(y, chr, start, end)
> foverlaps(x, y, by.x=c("seq", "start", "end"),
+             type="any", which=TRUE)
   xid yid
1:   1  NA
2:   2   2
3:   3   3
4:   4   3
5:   5   3
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("foverlaps", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("frank")
> ### * frank
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: frank
> ### Title: Fast rank
> ### Aliases: frank frankv rank
> ### Keywords: data
> 
> ### ** Examples
> 
> # on vectors
> x = c(4, 1, 4, NA, 1, NA, 4)
> # NAs are considered identical (unlike base R)
> # default is average
> frankv(x) # na.last=TRUE
[1] 4.0 1.5 4.0 6.5 1.5 6.5 4.0
> frankv(x, na.last=FALSE)
[1] 6.0 3.5 6.0 1.5 3.5 1.5 6.0
> 
> # ties.method = min
> frankv(x, ties.method="min")
[1] 3 1 3 6 1 6 3
> # ties.method = dense
> frankv(x, ties.method="dense")
[1] 2 1 2 3 1 3 2
> 
> # on data.table
> DT = data.table(x, y=c(1, 1, 1, 0, NA, 0, 2))
> frankv(DT, cols="x") # same as frankv(x) from before
[1] 4.0 1.5 4.0 6.5 1.5 6.5 4.0
> frankv(DT, cols="x", na.last="keep")
[1] 4.0 1.5 4.0  NA 1.5  NA 4.0
> frankv(DT, cols="x", ties.method="dense", na.last=NA)
[1] 2 1 2 1 2
> frank(DT, x, ties.method="dense", na.last=NA) # equivalent of above using frank
[1] 2 1 2 1 2
> # on both columns
> frankv(DT, ties.method="first", na.last="keep")
[1]  2  1  3 NA NA NA  4
> frank(DT, ties.method="first", na.last="keep") # equivalent of above using frank
[1]  2  1  3 NA NA NA  4
> 
> # order argument
> frank(DT, x, -y, ties.method="first")
[1] 4 1 5 6 2 7 3
> # equivalent of above using frankv
> frankv(DT, order=c(1L, -1L), ties.method="first")
[1] 4 1 5 6 2 7 3
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("frank", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("fread")
> ### * fread
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: fread
> ### Title: Fast and friendly file finagler
> ### Aliases: fread
> ### Keywords: data
> 
> ### ** Examples
> 
> ## Not run: 
> ##D 
> ##D # Demo speed-up
> ##D n = 1e6
> ##D DT = data.table( a=sample(1:1000,n,replace=TRUE),
> ##D                  b=sample(1:1000,n,replace=TRUE),
> ##D                  c=rnorm(n),
> ##D                  d=sample(c("foo","bar","baz","qux","quux"),n,replace=TRUE),
> ##D                  e=rnorm(n),
> ##D                  f=sample(1:1000,n,replace=TRUE) )
> ##D DT[2,b:=NA_integer_]
> ##D DT[4,c:=NA_real_]
> ##D DT[3,d:=NA_character_]
> ##D DT[5,d:=""]
> ##D DT[2,e:=+Inf]
> ##D DT[3,e:=-Inf]
> ##D 
> ##D write.table(DT,"test.csv",sep=",",row.names=FALSE,quote=FALSE)
> ##D cat("File size (MB):", round(file.info("test.csv")$size/1024^2),"\n")
> ##D # 50 MB (1e6 rows x 6 columns)
> ##D 
> ##D system.time(DF1 <-read.csv("test.csv",stringsAsFactors=FALSE))
> ##D # 60 sec (first time in fresh R session)
> ##D 
> ##D system.time(DF1 <- read.csv("test.csv",stringsAsFactors=FALSE))
> ##D # 30 sec (immediate repeat is faster, varies)
> ##D 
> ##D system.time(DF2 <- read.table("test.csv",header=TRUE,sep=",",quote="",
> ##D     stringsAsFactors=FALSE,comment.char="",nrows=n,
> ##D     colClasses=c("integer","integer","numeric",
> ##D                  "character","numeric","integer")))
> ##D # 10 sec (consistently). All known tricks and known nrows, see references.
> ##D 
> ##D require(data.table)
> ##D if(all(sapply(c("sqldf", "ff"), requireNamespace, quietly = TRUE))) {
> ##D   require(sqldf)
> ##D   require(ff)
> ##D 
> ##D   system.time(DT <- fread("test.csv"))
> ##D   #  3 sec (faster and friendlier)
> ##D 
> ##D   system.time(SQLDF <- read.csv.sql("test.csv",dbname=NULL))
> ##D   # 20 sec (friendly too, good defaults)
> ##D 
> ##D   system.time(FFDF <- read.csv.ffdf(file="test.csv",nrows=n))
> ##D   # 20 sec (friendly too, good defaults)
> ##D 
> ##D   identical(DF1,DF2)
> ##D   all.equal(as.data.table(DF1), DT)
> ##D   identical(DF1,within(SQLDF,{b<-as.integer(b);c<-as.numeric(c)}))
> ##D   identical(DF1,within(as.data.frame(FFDF),d<-as.character(d)))
> ##D }
> ##D 
> ##D # Scaling up ...
> ##D l = vector("list",10)
> ##D for (i in 1:10) l[[i]] = DT
> ##D DTbig = rbindlist(l)
> ##D tables()
> ##D write.table(DTbig,"testbig.csv",sep=",",row.names=FALSE,quote=FALSE)
> ##D # 500MB (10 million rows x 6 columns)
> ##D 
> ##D system.time(DF <- read.table("testbig.csv",header=TRUE,sep=",",
> ##D     quote="",stringsAsFactors=FALSE,comment.char="",nrows=1e7,
> ##D     colClasses=c("integer","integer","numeric",
> ##D                  "character","numeric","integer")))
> ##D # 100-200 sec (varies)
> ##D 
> ##D system.time(DT <- fread("testbig.csv"))
> ##D # 30-40 sec
> ##D 
> ##D all(mapply(all.equal, DF, DT))
> ##D 
> ##D 
> ##D # Real data example (Airline data)
> ##D # http://stat-computing.org/dataexpo/2009/the-data.html
> ##D 
> ##D download.file("http://stat-computing.org/dataexpo/2009/2008.csv.bz2",
> ##D               destfile="2008.csv.bz2")
> ##D # 109MB (compressed)
> ##D 
> ##D system("bunzip2 2008.csv.bz2")
> ##D # 658MB (7,009,728 rows x 29 columns)
> ##D 
> ##D colClasses = sapply(read.csv("2008.csv",nrows=100),class)
> ##D # 4 character, 24 integer, 1 logical. Incorrect.
> ##D 
> ##D colClasses = sapply(read.csv("2008.csv",nrows=200),class)
> ##D # 5 character, 24 integer. Correct. Might have missed data only using 100 rows
> ##D # since read.table assumes colClasses is correct.
> ##D 
> ##D system.time(DF <- read.table("2008.csv", header=TRUE, sep=",",
> ##D     quote="",stringsAsFactors=FALSE,comment.char="",nrows=7009730,
> ##D     colClasses=colClasses))
> ##D # 360 secs
> ##D 
> ##D system.time(DT <- fread("2008.csv"))
> ##D #  40 secs
> ##D 
> ##D table(sapply(DT,class))
> ##D # 5 character and 24 integer columns. Correct without needing to worry about colClasses
> ##D # issue above.
> ##D 
> ##D 
> ##D # Reads URLs directly :
> ##D fread("http://www.stats.ox.ac.uk/pub/datasets/csb/ch11b.dat")
> ##D 
> ##D # Decompresses .gz and .bz2 automatically :
> ##D fread("http://stat-computing.org/dataexpo/2009/2008.csv.bz2")
> ##D 
> ## End(Not run)
> 
> # Reads text input directly :
> fread("A,B\n1,2\n3,4")
   A B
1: 1 2
2: 3 4
> 
> # Reads pasted input directly :
> fread("A,B
+ 1,2
+ 3,4
+ ")
   A B
1: 1 2
2: 3 4
> 
> # Finds the first data line automatically :
> fread("
+ This is perhaps a banner line or two or ten.
+ A,B
+ 1,2
+ 3,4
+ ")
   A B
1: 1 2
2: 3 4
> 
> # Detects whether column names are present automatically :
> fread("
+ 1,2
+ 3,4
+ ")
   V1 V2
1:  1  2
2:  3  4
> 
> # Numerical precision :
> 
> DT = fread("A\n1.010203040506070809010203040506\n")
> # TODO: add numerals=c("allow.loss", "warn.loss", "no.loss") from base::read.table, +"use.Rmpfr"
> typeof(DT$A)=="double"   # currently "allow.loss" with no option
[1] TRUE
> 
> DT = fread("A\n1.46761e-313\n")   # read as 'numeric'
> DT[,sprintf("%.15E",A)]   # beyond what double precision can store accurately to 15 digits
[1] "1.467610000018072E-313"
> # For greater accuracy use colClasses to read as character, then package Rmpfr.
> 
> # colClasses
> data = "A,B,C,D\n1,3,5,7\n2,4,6,8\n"
> fread(data, colClasses=c(B="character",C="character",D="character"))  # as read.csv
   A B C D
1: 1 3 5 7
2: 2 4 6 8
> fread(data, colClasses=list(character=c("B","C","D")))    # saves typing
   A B C D
1: 1 3 5 7
2: 2 4 6 8
> fread(data, colClasses=list(character=2:4))     # same using column numbers
   A B C D
1: 1 3 5 7
2: 2 4 6 8
> 
> # drop
> fread(data, colClasses=c("B"="NULL","C"="NULL"))   # as read.csv
   A D
1: 1 7
2: 2 8
> fread(data, colClasses=list(NULL=c("B","C")))      #
   A D
1: 1 7
2: 2 8
> fread(data, drop=c("B","C"))      # same but less typing, easier to read
   A D
1: 1 7
2: 2 8
> fread(data, drop=2:3)             # same using column numbers
   A D
1: 1 7
2: 2 8
> 
> # select
> # (in read.csv you need to work out which to drop)
> fread(data, select=c("A","D"))    # less typing, easier to read
   A D
1: 1 7
2: 2 8
> fread(data, select=c(1,4))        # same using column numbers
   A D
1: 1 7
2: 2 8
> 
> # skip blank lines
> fread("a,b\n1,a\n2,b\n\n\n3,c\n", blank.lines.skip=TRUE)
   a b
1: 1 a
2: 2 b
3: 3 c
> # fill
> fread("a,b\n1,a\n2\n3,c\n", fill=TRUE)
   a b
1: 1 a
2: 2  
3: 3 c
> fread("a,b\n\n1,a\n2\n\n3,c\n\n", fill=TRUE)
    a b
1: NA  
2:  1 a
3:  2  
4: NA  
5:  3 c
6: NA  
> 
> # fill with skip blank lines
> fread("a,b\n\n1,a\n2\n\n3,c\n\n", fill=TRUE, blank.lines.skip=TRUE)
   a b
1: 1 a
2: 2  
3: 3 c
> 
> # check.names usage
> fread("a b,a b\n1,2\n")
   a b a b
1:   1   2
> fread("a b,a b\n1,2\n", check.names=TRUE) # no duplicates + syntactically valid names
   a.b a.b.1
1:   1     2
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("fread", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("froll")
> ### * froll
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: roll
> ### Title: Rolling functions
> ### Aliases: roll froll rolling sliding moving frollmean frollsum
> ### Keywords: data
> 
> ### ** Examples
> 
> d = as.data.table(list(1:6/2, 3:8/4))
> # rollmean of single vector and single window
> frollmean(d[, V1], 3)
[1]  NA  NA 1.0 1.5 2.0 2.5
> # multiple columns at once
> frollmean(d, 3)
[[1]]
[1]  NA  NA 1.0 1.5 2.0 2.5

[[2]]
[1]   NA   NA 1.00 1.25 1.50 1.75

> # multiple windows at once
> frollmean(d[, .(V1)], c(3, 4))
[[1]]
[1]  NA  NA 1.0 1.5 2.0 2.5

[[2]]
[1]   NA   NA   NA 1.25 1.75 2.25

> # multiple columns and multiple windows at once
> frollmean(d, c(3, 4))
[[1]]
[1]  NA  NA 1.0 1.5 2.0 2.5

[[2]]
[1]   NA   NA   NA 1.25 1.75 2.25

[[3]]
[1]   NA   NA 1.00 1.25 1.50 1.75

[[4]]
[1]    NA    NA    NA 1.125 1.375 1.625

> ## three calls above will use multiple cores when available
> 
> # partial window using adaptive rolling function
> an = function(n, len) c(seq.int(n), rep(n, len-n))
> n = an(3, nrow(d))
> frollmean(d, n, adaptive=TRUE)
[[1]]
[1] 0.50 0.75 1.00 1.50 2.00 2.50

[[2]]
[1] 0.750 0.875 1.000 1.250 1.500 1.750

> 
> # performance vs exactness
> set.seed(108)
> x = sample(c(rnorm(1e3, 1e6, 5e5), 5e9, 5e-9))
> n = 15
> ma = function(x, n, na.rm=FALSE) {
+   ans = rep(NA_real_, nx<-length(x))
+   for (i in n:nx) ans[i] = mean(x[(i-n+1):i], na.rm=na.rm)
+   ans
+ }
> fastma = function(x, n, na.rm) {
+   if (!missing(na.rm)) stop("NAs are unsupported, wrongly propagated by cumsum")
+   cs = cumsum(x)
+   scs = shift(cs, n)
+   scs[n] = 0
+   as.double((cs-scs)/n)
+ }
> system.time(ans1<-ma(x, n))
   user  system elapsed 
  0.087   0.002   0.008 
> system.time(ans2<-fastma(x, n))
   user  system elapsed 
  0.002   0.001   0.000 
> system.time(ans3<-frollmean(x, n, algo="exact")) # parallel using openmp again
   user  system elapsed 
  0.001   0.000   0.000 
> system.time(ans4<-frollmean(x, n))
   user  system elapsed 
  0.002   0.000   0.000 
> anserr = list(
+   froll_exact_f = ans4-ans1,
+   froll_exact_t = ans3-ans1,
+   fastma = ans2-ans1
+ )
> errs = sapply(lapply(anserr, abs), sum, na.rm=TRUE)
> sapply(errs, format, scientific=FALSE) # roundoff
     froll_exact_f      froll_exact_t             fastma 
"0.00000006740447"                "0"    "0.00001854484" 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("froll", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("fsort")
> ### * fsort
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: fsort
> ### Title: Fast parallel sort
> ### Aliases: fsort
> 
> ### ** Examples
> 
> x = runif(1e6)
> system.time(ans1 <- sort(x, method="quick"))
   user  system elapsed 
  0.994   0.020   0.088 
> system.time(ans2 <- fsort(x))
   user  system elapsed 
  0.187   0.042   0.022 
> identical(ans1, ans2)
[1] TRUE
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("fsort", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("fwrite")
> ### * fwrite
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: fwrite
> ### Title: Fast CSV writer
> ### Aliases: fwrite
> ### Keywords: data
> 
> ### ** Examples
> 
> 
> DF = data.frame(A=1:3, B=c("foo","A,Name","baz"))
> fwrite(DF)
A,B
1,foo
2,"A,Name"
3,baz
> write.csv(DF, row.names=FALSE, quote=FALSE)  # same
A,B
1,foo
2,A,Name
3,baz
> 
> fwrite(DF, row.names=TRUE, quote=TRUE)
"","A","B"
"1",1,"foo"
"2",2,"A,Name"
"3",3,"baz"
> write.csv(DF)                                # same
"","A","B"
"1",1,"foo"
"2",2,"A,Name"
"3",3,"baz"
> 
> DF = data.frame(A=c(2.1,-1.234e-307,pi), B=c("foo","A,Name","bar"))
> fwrite(DF, quote='auto')        # Just DF[2,2] is auto quoted
A,B
2.1,foo
-1.234e-307,"A,Name"
3.14159265358979,bar
> write.csv(DF, row.names=FALSE)  # same numeric formatting
"A","B"
2.1,"foo"
-1.234e-307,"A,Name"
3.14159265358979,"bar"
> 
> DT = data.table(A=c(2,5.6,-3),B=list(1:3,c("foo","A,Name","bar"),round(pi*1:3,2)))
> fwrite(DT)
A,B
2,1|2|3
5.6,foo|"A,Name"|bar
-3,3.14|6.28|9.42
> fwrite(DT, sep="|", sep2=c("{",",","}"))
A|B
2|{1,2,3}
5.6|{foo,"A,Name",bar}
-3|{3.14,6.28,9.42}
> 
> ## Not run: 
> ##D 
> ##D set.seed(1)
> ##D DT = as.data.table( lapply(1:10, sample,
> ##D          x=as.numeric(1:5e7), size=5e6))                            #     382MB
> ##D system.time(fwrite(DT, "/dev/shm/tmp1.csv"))                        #      0.8s
> ##D system.time(write.csv(DT, "/dev/shm/tmp2.csv",                      #     60.6s
> ##D                       quote=FALSE, row.names=FALSE))
> ##D system("diff /dev/shm/tmp1.csv /dev/shm/tmp2.csv")                  # identical
> ##D 
> ##D set.seed(1)
> ##D N = 1e7
> ##D DT = data.table(
> ##D   str1=sample(sprintf("%010d",sample(N,1e5,replace=TRUE)), N, replace=TRUE),
> ##D   str2=sample(sprintf("%09d",sample(N,1e5,replace=TRUE)), N, replace=TRUE),
> ##D   str3=sample(sapply(sample(2:30, 100, TRUE), function(n)
> ##D      paste0(sample(LETTERS, n, TRUE), collapse="")), N, TRUE),
> ##D   str4=sprintf("%05d",sample(sample(1e5,50),N,TRUE)),
> ##D   num1=sample(round(rnorm(1e6,mean=6.5,sd=15),2), N, replace=TRUE),
> ##D   num2=sample(round(rnorm(1e6,mean=6.5,sd=15),10), N, replace=TRUE),
> ##D   str5=sample(c("Y","N"),N,TRUE),
> ##D   str6=sample(c("M","F"),N,TRUE),
> ##D   int1=sample(ceiling(rexp(1e6)), N, replace=TRUE),
> ##D   int2=sample(N,N,replace=TRUE)-N/2
> ##D )                                                                   #     774MB
> ##D system.time(fwrite(DT,"/dev/shm/tmp1.csv"))                         #      1.1s
> ##D system.time(write.csv(DT,"/dev/shm/tmp2.csv",                       #     63.2s
> ##D                       row.names=FALSE, quote=FALSE))
> ##D system("diff /dev/shm/tmp1.csv /dev/shm/tmp2.csv")                  # identical
> ##D 
> ##D unlink("/dev/shm/tmp1.csv")
> ##D unlink("/dev/shm/tmp2.csv")
> ## End(Not run)
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("fwrite", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("groupingsets")
> ### * groupingsets
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: groupingsets
> ### Title: Grouping Set aggregation for data tables
> ### Aliases: rollup cube groupingsets rollup.data.table cube.data.table
> ###   groupingsets.data.table
> ### Keywords: data
> 
> ### ** Examples
> 
> n = 24L
> set.seed(25)
> DT <- data.table(
+     color = sample(c("green","yellow","red"), n, TRUE),
+     year = as.Date(sample(paste0(2011:2015,"-01-01"), n, TRUE)),
+     status = as.factor(sample(c("removed","active","inactive","archived"), n, TRUE)),
+     amount = sample(1:5, n, TRUE),
+     value = sample(c(3, 3.5, 2.5, 2), n, TRUE)
+ )
> 
> # rollup
> rollup(DT, j = sum(value), by = c("color","year","status")) # default id=FALSE
     color       year   status   V1
 1: yellow 2012-01-01  removed 11.0
 2:    red 2012-01-01 inactive  2.0
 3:  green 2011-01-01  removed  3.0
 4:    red 2013-01-01 inactive  3.0
 5:  green 2013-01-01 archived  2.5
 6:    red 2012-01-01   active  3.5
 7: yellow 2015-01-01 inactive  2.5
 8:  green 2012-01-01  removed  3.0
 9:  green 2011-01-01 inactive  5.5
10:  green 2015-01-01  removed  3.5
11: yellow 2013-01-01  removed  2.5
12:    red 2015-01-01  removed  2.0
13:    red 2011-01-01   active  3.0
14: yellow 2014-01-01 inactive  3.0
15:    red 2012-01-01 archived  3.0
16: yellow 2013-01-01   active  3.0
17:    red 2014-01-01 archived  3.0
18:  green 2013-01-01 inactive  2.0
19:  green 2015-01-01 archived  3.0
20:  green 2014-01-01  removed  3.0
21: yellow 2012-01-01     <NA> 11.0
22:    red 2012-01-01     <NA>  8.5
23:  green 2011-01-01     <NA>  8.5
24:    red 2013-01-01     <NA>  3.0
25:  green 2013-01-01     <NA>  4.5
26: yellow 2015-01-01     <NA>  2.5
27:  green 2012-01-01     <NA>  3.0
28:  green 2015-01-01     <NA>  6.5
29: yellow 2013-01-01     <NA>  5.5
30:    red 2015-01-01     <NA>  2.0
31:    red 2011-01-01     <NA>  3.0
32: yellow 2014-01-01     <NA>  3.0
33:    red 2014-01-01     <NA>  3.0
34:  green 2014-01-01     <NA>  3.0
35: yellow       <NA>     <NA> 22.0
36:    red       <NA>     <NA> 19.5
37:  green       <NA>     <NA> 25.5
38:   <NA>       <NA>     <NA> 67.0
     color       year   status   V1
> rollup(DT, j = sum(value), by = c("color","year","status"), id=TRUE)
    grouping  color       year   status   V1
 1:        0 yellow 2012-01-01  removed 11.0
 2:        0    red 2012-01-01 inactive  2.0
 3:        0  green 2011-01-01  removed  3.0
 4:        0    red 2013-01-01 inactive  3.0
 5:        0  green 2013-01-01 archived  2.5
 6:        0    red 2012-01-01   active  3.5
 7:        0 yellow 2015-01-01 inactive  2.5
 8:        0  green 2012-01-01  removed  3.0
 9:        0  green 2011-01-01 inactive  5.5
10:        0  green 2015-01-01  removed  3.5
11:        0 yellow 2013-01-01  removed  2.5
12:        0    red 2015-01-01  removed  2.0
13:        0    red 2011-01-01   active  3.0
14:        0 yellow 2014-01-01 inactive  3.0
15:        0    red 2012-01-01 archived  3.0
16:        0 yellow 2013-01-01   active  3.0
17:        0    red 2014-01-01 archived  3.0
18:        0  green 2013-01-01 inactive  2.0
19:        0  green 2015-01-01 archived  3.0
20:        0  green 2014-01-01  removed  3.0
21:        1 yellow 2012-01-01     <NA> 11.0
22:        1    red 2012-01-01     <NA>  8.5
23:        1  green 2011-01-01     <NA>  8.5
24:        1    red 2013-01-01     <NA>  3.0
25:        1  green 2013-01-01     <NA>  4.5
26:        1 yellow 2015-01-01     <NA>  2.5
27:        1  green 2012-01-01     <NA>  3.0
28:        1  green 2015-01-01     <NA>  6.5
29:        1 yellow 2013-01-01     <NA>  5.5
30:        1    red 2015-01-01     <NA>  2.0
31:        1    red 2011-01-01     <NA>  3.0
32:        1 yellow 2014-01-01     <NA>  3.0
33:        1    red 2014-01-01     <NA>  3.0
34:        1  green 2014-01-01     <NA>  3.0
35:        3 yellow       <NA>     <NA> 22.0
36:        3    red       <NA>     <NA> 19.5
37:        3  green       <NA>     <NA> 25.5
38:        7   <NA>       <NA>     <NA> 67.0
    grouping  color       year   status   V1
> rollup(DT, j = lapply(.SD, sum), by = c("color","year","status"), id=TRUE, .SDcols="value")
    grouping  color       year   status value
 1:        0 yellow 2012-01-01  removed  11.0
 2:        0    red 2012-01-01 inactive   2.0
 3:        0  green 2011-01-01  removed   3.0
 4:        0    red 2013-01-01 inactive   3.0
 5:        0  green 2013-01-01 archived   2.5
 6:        0    red 2012-01-01   active   3.5
 7:        0 yellow 2015-01-01 inactive   2.5
 8:        0  green 2012-01-01  removed   3.0
 9:        0  green 2011-01-01 inactive   5.5
10:        0  green 2015-01-01  removed   3.5
11:        0 yellow 2013-01-01  removed   2.5
12:        0    red 2015-01-01  removed   2.0
13:        0    red 2011-01-01   active   3.0
14:        0 yellow 2014-01-01 inactive   3.0
15:        0    red 2012-01-01 archived   3.0
16:        0 yellow 2013-01-01   active   3.0
17:        0    red 2014-01-01 archived   3.0
18:        0  green 2013-01-01 inactive   2.0
19:        0  green 2015-01-01 archived   3.0
20:        0  green 2014-01-01  removed   3.0
21:        1 yellow 2012-01-01     <NA>  11.0
22:        1    red 2012-01-01     <NA>   8.5
23:        1  green 2011-01-01     <NA>   8.5
24:        1    red 2013-01-01     <NA>   3.0
25:        1  green 2013-01-01     <NA>   4.5
26:        1 yellow 2015-01-01     <NA>   2.5
27:        1  green 2012-01-01     <NA>   3.0
28:        1  green 2015-01-01     <NA>   6.5
29:        1 yellow 2013-01-01     <NA>   5.5
30:        1    red 2015-01-01     <NA>   2.0
31:        1    red 2011-01-01     <NA>   3.0
32:        1 yellow 2014-01-01     <NA>   3.0
33:        1    red 2014-01-01     <NA>   3.0
34:        1  green 2014-01-01     <NA>   3.0
35:        3 yellow       <NA>     <NA>  22.0
36:        3    red       <NA>     <NA>  19.5
37:        3  green       <NA>     <NA>  25.5
38:        7   <NA>       <NA>     <NA>  67.0
    grouping  color       year   status value
> rollup(DT, j = c(list(count=.N), lapply(.SD, sum)), by = c("color","year","status"), id=TRUE)
    grouping  color       year   status count amount value
 1:        0 yellow 2012-01-01  removed     4     10  11.0
 2:        0    red 2012-01-01 inactive     1      4   2.0
 3:        0  green 2011-01-01  removed     1      2   3.0
 4:        0    red 2013-01-01 inactive     1      3   3.0
 5:        0  green 2013-01-01 archived     1      1   2.5
 6:        0    red 2012-01-01   active     1      5   3.5
 7:        0 yellow 2015-01-01 inactive     1      1   2.5
 8:        0  green 2012-01-01  removed     1      4   3.0
 9:        0  green 2011-01-01 inactive     2      4   5.5
10:        0  green 2015-01-01  removed     1      3   3.5
11:        0 yellow 2013-01-01  removed     1      1   2.5
12:        0    red 2015-01-01  removed     1      5   2.0
13:        0    red 2011-01-01   active     1      2   3.0
14:        0 yellow 2014-01-01 inactive     1      4   3.0
15:        0    red 2012-01-01 archived     1      3   3.0
16:        0 yellow 2013-01-01   active     1      3   3.0
17:        0    red 2014-01-01 archived     1      2   3.0
18:        0  green 2013-01-01 inactive     1      4   2.0
19:        0  green 2015-01-01 archived     1      1   3.0
20:        0  green 2014-01-01  removed     1      2   3.0
21:        1 yellow 2012-01-01     <NA>     4     10  11.0
22:        1    red 2012-01-01     <NA>     3     12   8.5
23:        1  green 2011-01-01     <NA>     3      6   8.5
24:        1    red 2013-01-01     <NA>     1      3   3.0
25:        1  green 2013-01-01     <NA>     2      5   4.5
26:        1 yellow 2015-01-01     <NA>     1      1   2.5
27:        1  green 2012-01-01     <NA>     1      4   3.0
28:        1  green 2015-01-01     <NA>     2      4   6.5
29:        1 yellow 2013-01-01     <NA>     2      4   5.5
30:        1    red 2015-01-01     <NA>     1      5   2.0
31:        1    red 2011-01-01     <NA>     1      2   3.0
32:        1 yellow 2014-01-01     <NA>     1      4   3.0
33:        1    red 2014-01-01     <NA>     1      2   3.0
34:        1  green 2014-01-01     <NA>     1      2   3.0
35:        3 yellow       <NA>     <NA>     8     19  22.0
36:        3    red       <NA>     <NA>     7     24  19.5
37:        3  green       <NA>     <NA>     9     21  25.5
38:        7   <NA>       <NA>     <NA>    24     64  67.0
    grouping  color       year   status count amount value
> 
> # cube
> cube(DT, j = sum(value), by = c("color","year","status"), id=TRUE)
    grouping  color       year   status   V1
 1:        0 yellow 2012-01-01  removed 11.0
 2:        0    red 2012-01-01 inactive  2.0
 3:        0  green 2011-01-01  removed  3.0
 4:        0    red 2013-01-01 inactive  3.0
 5:        0  green 2013-01-01 archived  2.5
 6:        0    red 2012-01-01   active  3.5
 7:        0 yellow 2015-01-01 inactive  2.5
 8:        0  green 2012-01-01  removed  3.0
 9:        0  green 2011-01-01 inactive  5.5
10:        0  green 2015-01-01  removed  3.5
11:        0 yellow 2013-01-01  removed  2.5
12:        0    red 2015-01-01  removed  2.0
13:        0    red 2011-01-01   active  3.0
14:        0 yellow 2014-01-01 inactive  3.0
15:        0    red 2012-01-01 archived  3.0
16:        0 yellow 2013-01-01   active  3.0
17:        0    red 2014-01-01 archived  3.0
18:        0  green 2013-01-01 inactive  2.0
19:        0  green 2015-01-01 archived  3.0
20:        0  green 2014-01-01  removed  3.0
21:        1 yellow 2012-01-01     <NA> 11.0
22:        1    red 2012-01-01     <NA>  8.5
23:        1  green 2011-01-01     <NA>  8.5
24:        1    red 2013-01-01     <NA>  3.0
25:        1  green 2013-01-01     <NA>  4.5
26:        1 yellow 2015-01-01     <NA>  2.5
27:        1  green 2012-01-01     <NA>  3.0
28:        1  green 2015-01-01     <NA>  6.5
29:        1 yellow 2013-01-01     <NA>  5.5
30:        1    red 2015-01-01     <NA>  2.0
31:        1    red 2011-01-01     <NA>  3.0
32:        1 yellow 2014-01-01     <NA>  3.0
33:        1    red 2014-01-01     <NA>  3.0
34:        1  green 2014-01-01     <NA>  3.0
35:        2 yellow       <NA>  removed 13.5
36:        2    red       <NA> inactive  5.0
37:        2  green       <NA>  removed 12.5
38:        2  green       <NA> archived  5.5
39:        2    red       <NA>   active  6.5
40:        2 yellow       <NA> inactive  5.5
41:        2  green       <NA> inactive  7.5
42:        2    red       <NA>  removed  2.0
43:        2    red       <NA> archived  6.0
44:        2 yellow       <NA>   active  3.0
45:        3 yellow       <NA>     <NA> 22.0
46:        3    red       <NA>     <NA> 19.5
47:        3  green       <NA>     <NA> 25.5
48:        4   <NA> 2012-01-01  removed 14.0
49:        4   <NA> 2012-01-01 inactive  2.0
50:        4   <NA> 2011-01-01  removed  3.0
51:        4   <NA> 2013-01-01 inactive  5.0
52:        4   <NA> 2013-01-01 archived  2.5
53:        4   <NA> 2012-01-01   active  3.5
54:        4   <NA> 2015-01-01 inactive  2.5
55:        4   <NA> 2011-01-01 inactive  5.5
56:        4   <NA> 2015-01-01  removed  5.5
57:        4   <NA> 2013-01-01  removed  2.5
58:        4   <NA> 2011-01-01   active  3.0
59:        4   <NA> 2014-01-01 inactive  3.0
60:        4   <NA> 2012-01-01 archived  3.0
61:        4   <NA> 2013-01-01   active  3.0
62:        4   <NA> 2014-01-01 archived  3.0
63:        4   <NA> 2015-01-01 archived  3.0
64:        4   <NA> 2014-01-01  removed  3.0
65:        5   <NA> 2012-01-01     <NA> 22.5
66:        5   <NA> 2011-01-01     <NA> 11.5
67:        5   <NA> 2013-01-01     <NA> 13.0
68:        5   <NA> 2015-01-01     <NA> 11.0
69:        5   <NA> 2014-01-01     <NA>  9.0
70:        6   <NA>       <NA>  removed 28.0
71:        6   <NA>       <NA> inactive 18.0
72:        6   <NA>       <NA> archived 11.5
73:        6   <NA>       <NA>   active  9.5
74:        7   <NA>       <NA>     <NA> 67.0
    grouping  color       year   status   V1
> cube(DT, j = lapply(.SD, sum), by = c("color","year","status"), id=TRUE, .SDcols="value")
    grouping  color       year   status value
 1:        0 yellow 2012-01-01  removed  11.0
 2:        0    red 2012-01-01 inactive   2.0
 3:        0  green 2011-01-01  removed   3.0
 4:        0    red 2013-01-01 inactive   3.0
 5:        0  green 2013-01-01 archived   2.5
 6:        0    red 2012-01-01   active   3.5
 7:        0 yellow 2015-01-01 inactive   2.5
 8:        0  green 2012-01-01  removed   3.0
 9:        0  green 2011-01-01 inactive   5.5
10:        0  green 2015-01-01  removed   3.5
11:        0 yellow 2013-01-01  removed   2.5
12:        0    red 2015-01-01  removed   2.0
13:        0    red 2011-01-01   active   3.0
14:        0 yellow 2014-01-01 inactive   3.0
15:        0    red 2012-01-01 archived   3.0
16:        0 yellow 2013-01-01   active   3.0
17:        0    red 2014-01-01 archived   3.0
18:        0  green 2013-01-01 inactive   2.0
19:        0  green 2015-01-01 archived   3.0
20:        0  green 2014-01-01  removed   3.0
21:        1 yellow 2012-01-01     <NA>  11.0
22:        1    red 2012-01-01     <NA>   8.5
23:        1  green 2011-01-01     <NA>   8.5
24:        1    red 2013-01-01     <NA>   3.0
25:        1  green 2013-01-01     <NA>   4.5
26:        1 yellow 2015-01-01     <NA>   2.5
27:        1  green 2012-01-01     <NA>   3.0
28:        1  green 2015-01-01     <NA>   6.5
29:        1 yellow 2013-01-01     <NA>   5.5
30:        1    red 2015-01-01     <NA>   2.0
31:        1    red 2011-01-01     <NA>   3.0
32:        1 yellow 2014-01-01     <NA>   3.0
33:        1    red 2014-01-01     <NA>   3.0
34:        1  green 2014-01-01     <NA>   3.0
35:        2 yellow       <NA>  removed  13.5
36:        2    red       <NA> inactive   5.0
37:        2  green       <NA>  removed  12.5
38:        2  green       <NA> archived   5.5
39:        2    red       <NA>   active   6.5
40:        2 yellow       <NA> inactive   5.5
41:        2  green       <NA> inactive   7.5
42:        2    red       <NA>  removed   2.0
43:        2    red       <NA> archived   6.0
44:        2 yellow       <NA>   active   3.0
45:        3 yellow       <NA>     <NA>  22.0
46:        3    red       <NA>     <NA>  19.5
47:        3  green       <NA>     <NA>  25.5
48:        4   <NA> 2012-01-01  removed  14.0
49:        4   <NA> 2012-01-01 inactive   2.0
50:        4   <NA> 2011-01-01  removed   3.0
51:        4   <NA> 2013-01-01 inactive   5.0
52:        4   <NA> 2013-01-01 archived   2.5
53:        4   <NA> 2012-01-01   active   3.5
54:        4   <NA> 2015-01-01 inactive   2.5
55:        4   <NA> 2011-01-01 inactive   5.5
56:        4   <NA> 2015-01-01  removed   5.5
57:        4   <NA> 2013-01-01  removed   2.5
58:        4   <NA> 2011-01-01   active   3.0
59:        4   <NA> 2014-01-01 inactive   3.0
60:        4   <NA> 2012-01-01 archived   3.0
61:        4   <NA> 2013-01-01   active   3.0
62:        4   <NA> 2014-01-01 archived   3.0
63:        4   <NA> 2015-01-01 archived   3.0
64:        4   <NA> 2014-01-01  removed   3.0
65:        5   <NA> 2012-01-01     <NA>  22.5
66:        5   <NA> 2011-01-01     <NA>  11.5
67:        5   <NA> 2013-01-01     <NA>  13.0
68:        5   <NA> 2015-01-01     <NA>  11.0
69:        5   <NA> 2014-01-01     <NA>   9.0
70:        6   <NA>       <NA>  removed  28.0
71:        6   <NA>       <NA> inactive  18.0
72:        6   <NA>       <NA> archived  11.5
73:        6   <NA>       <NA>   active   9.5
74:        7   <NA>       <NA>     <NA>  67.0
    grouping  color       year   status value
> cube(DT, j = c(list(count=.N), lapply(.SD, sum)), by = c("color","year","status"), id=TRUE)
    grouping  color       year   status count amount value
 1:        0 yellow 2012-01-01  removed     4     10  11.0
 2:        0    red 2012-01-01 inactive     1      4   2.0
 3:        0  green 2011-01-01  removed     1      2   3.0
 4:        0    red 2013-01-01 inactive     1      3   3.0
 5:        0  green 2013-01-01 archived     1      1   2.5
 6:        0    red 2012-01-01   active     1      5   3.5
 7:        0 yellow 2015-01-01 inactive     1      1   2.5
 8:        0  green 2012-01-01  removed     1      4   3.0
 9:        0  green 2011-01-01 inactive     2      4   5.5
10:        0  green 2015-01-01  removed     1      3   3.5
11:        0 yellow 2013-01-01  removed     1      1   2.5
12:        0    red 2015-01-01  removed     1      5   2.0
13:        0    red 2011-01-01   active     1      2   3.0
14:        0 yellow 2014-01-01 inactive     1      4   3.0
15:        0    red 2012-01-01 archived     1      3   3.0
16:        0 yellow 2013-01-01   active     1      3   3.0
17:        0    red 2014-01-01 archived     1      2   3.0
18:        0  green 2013-01-01 inactive     1      4   2.0
19:        0  green 2015-01-01 archived     1      1   3.0
20:        0  green 2014-01-01  removed     1      2   3.0
21:        1 yellow 2012-01-01     <NA>     4     10  11.0
22:        1    red 2012-01-01     <NA>     3     12   8.5
23:        1  green 2011-01-01     <NA>     3      6   8.5
24:        1    red 2013-01-01     <NA>     1      3   3.0
25:        1  green 2013-01-01     <NA>     2      5   4.5
26:        1 yellow 2015-01-01     <NA>     1      1   2.5
27:        1  green 2012-01-01     <NA>     1      4   3.0
28:        1  green 2015-01-01     <NA>     2      4   6.5
29:        1 yellow 2013-01-01     <NA>     2      4   5.5
30:        1    red 2015-01-01     <NA>     1      5   2.0
31:        1    red 2011-01-01     <NA>     1      2   3.0
32:        1 yellow 2014-01-01     <NA>     1      4   3.0
33:        1    red 2014-01-01     <NA>     1      2   3.0
34:        1  green 2014-01-01     <NA>     1      2   3.0
35:        2 yellow       <NA>  removed     5     11  13.5
36:        2    red       <NA> inactive     2      7   5.0
37:        2  green       <NA>  removed     4     11  12.5
38:        2  green       <NA> archived     2      2   5.5
39:        2    red       <NA>   active     2      7   6.5
40:        2 yellow       <NA> inactive     2      5   5.5
41:        2  green       <NA> inactive     3      8   7.5
42:        2    red       <NA>  removed     1      5   2.0
43:        2    red       <NA> archived     2      5   6.0
44:        2 yellow       <NA>   active     1      3   3.0
45:        3 yellow       <NA>     <NA>     8     19  22.0
46:        3    red       <NA>     <NA>     7     24  19.5
47:        3  green       <NA>     <NA>     9     21  25.5
48:        4   <NA> 2012-01-01  removed     5     14  14.0
49:        4   <NA> 2012-01-01 inactive     1      4   2.0
50:        4   <NA> 2011-01-01  removed     1      2   3.0
51:        4   <NA> 2013-01-01 inactive     2      7   5.0
52:        4   <NA> 2013-01-01 archived     1      1   2.5
53:        4   <NA> 2012-01-01   active     1      5   3.5
54:        4   <NA> 2015-01-01 inactive     1      1   2.5
55:        4   <NA> 2011-01-01 inactive     2      4   5.5
56:        4   <NA> 2015-01-01  removed     2      8   5.5
57:        4   <NA> 2013-01-01  removed     1      1   2.5
58:        4   <NA> 2011-01-01   active     1      2   3.0
59:        4   <NA> 2014-01-01 inactive     1      4   3.0
60:        4   <NA> 2012-01-01 archived     1      3   3.0
61:        4   <NA> 2013-01-01   active     1      3   3.0
62:        4   <NA> 2014-01-01 archived     1      2   3.0
63:        4   <NA> 2015-01-01 archived     1      1   3.0
64:        4   <NA> 2014-01-01  removed     1      2   3.0
65:        5   <NA> 2012-01-01     <NA>     8     26  22.5
66:        5   <NA> 2011-01-01     <NA>     4      8  11.5
67:        5   <NA> 2013-01-01     <NA>     5     12  13.0
68:        5   <NA> 2015-01-01     <NA>     4     10  11.0
69:        5   <NA> 2014-01-01     <NA>     3      8   9.0
70:        6   <NA>       <NA>  removed    10     27  28.0
71:        6   <NA>       <NA> inactive     7     20  18.0
72:        6   <NA>       <NA> archived     4      7  11.5
73:        6   <NA>       <NA>   active     3     10   9.5
74:        7   <NA>       <NA>     <NA>    24     64  67.0
    grouping  color       year   status count amount value
> 
> # groupingsets
> groupingsets(DT, j = c(list(count=.N), lapply(.SD, sum)), by = c("color","year","status"),
+              sets = list("color", c("year","status"), character()), id=TRUE)
    grouping  color       year   status count amount value
 1:        3 yellow       <NA>     <NA>     8     19  22.0
 2:        3    red       <NA>     <NA>     7     24  19.5
 3:        3  green       <NA>     <NA>     9     21  25.5
 4:        4   <NA> 2012-01-01  removed     5     14  14.0
 5:        4   <NA> 2012-01-01 inactive     1      4   2.0
 6:        4   <NA> 2011-01-01  removed     1      2   3.0
 7:        4   <NA> 2013-01-01 inactive     2      7   5.0
 8:        4   <NA> 2013-01-01 archived     1      1   2.5
 9:        4   <NA> 2012-01-01   active     1      5   3.5
10:        4   <NA> 2015-01-01 inactive     1      1   2.5
11:        4   <NA> 2011-01-01 inactive     2      4   5.5
12:        4   <NA> 2015-01-01  removed     2      8   5.5
13:        4   <NA> 2013-01-01  removed     1      1   2.5
14:        4   <NA> 2011-01-01   active     1      2   3.0
15:        4   <NA> 2014-01-01 inactive     1      4   3.0
16:        4   <NA> 2012-01-01 archived     1      3   3.0
17:        4   <NA> 2013-01-01   active     1      3   3.0
18:        4   <NA> 2014-01-01 archived     1      2   3.0
19:        4   <NA> 2015-01-01 archived     1      1   3.0
20:        4   <NA> 2014-01-01  removed     1      2   3.0
21:        7   <NA>       <NA>     <NA>    24     64  67.0
    grouping  color       year   status count amount value
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("groupingsets", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("last")
> ### * last
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: last
> ### Title: Last item of an object
> ### Aliases: last
> ### Keywords: data
> 
> ### ** Examples
> 
> last(1:5) # [1] 5
[1] 5
> x = data.table(x=1:5, y=6:10)
> last(x) # same as x[5]
   x  y
1: 5 10
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("last", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("like")
> ### * like
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: like
> ### Title: Convenience function for calling regexpr.
> ### Aliases: like %like%
> ### Keywords: data
> 
> ### ** Examples
> 
> DT = data.table(Name=c("Mary","George","Martha"), Salary=c(2,3,4))
> DT[Name %like% "^Mar"]
     Name Salary
1:   Mary      2
2: Martha      4
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("like", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("melt.data.table")
> ### * melt.data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: melt.data.table
> ### Title: Fast melt for data.table
> ### Aliases: melt.data.table melt
> ### Keywords: data
> 
> ### ** Examples
> 
> set.seed(45)
> require(data.table)
> DT <- data.table(
+       i_1 = c(1:5, NA),
+       i_2 = c(NA,6,7,8,9,10),
+       f_1 = factor(sample(c(letters[1:3], NA), 6, TRUE)),
+       f_2 = factor(c("z", "a", "x", "c", "x", "x"), ordered=TRUE),
+       c_1 = sample(c(letters[1:3], NA), 6, TRUE),
+       d_1 = as.Date(c(1:3,NA,4:5), origin="2013-09-01"),
+       d_2 = as.Date(6:1, origin="2012-01-01"))
> # add a couple of list cols
> DT[, l_1 := DT[, list(c=list(rep(i_1, sample(5,1)))), by = i_1]$c]
> DT[, l_2 := DT[, list(c=list(rep(c_1, sample(5,1)))), by = i_1]$c]
> 
> # id, measure as character/integer/numeric vectors
> melt(DT, id=1:2, measure="f_1")
   i_1 i_2 variable value
1:   1  NA      f_1     c
2:   2   6      f_1     b
3:   3   7      f_1     a
4:   4   8      f_1     b
5:   5   9      f_1     b
6:  NA  10      f_1     b
> melt(DT, id=c("i_1", "i_2"), measure=3) # same as above
   i_1 i_2 variable value
1:   1  NA      f_1     c
2:   2   6      f_1     b
3:   3   7      f_1     a
4:   4   8      f_1     b
5:   5   9      f_1     b
6:  NA  10      f_1     b
> melt(DT, id=1:2, measure=3L, value.factor=TRUE) # same, but 'value' is factor
   i_1 i_2 variable value
1:   1  NA      f_1     c
2:   2   6      f_1     b
3:   3   7      f_1     a
4:   4   8      f_1     b
5:   5   9      f_1     b
6:  NA  10      f_1     b
> melt(DT, id=1:2, measure=3:4, value.factor=TRUE) # 'value' is *ordered* factor
    i_1 i_2 variable value
 1:   1  NA      f_1     c
 2:   2   6      f_1     b
 3:   3   7      f_1     a
 4:   4   8      f_1     b
 5:   5   9      f_1     b
 6:  NA  10      f_1     b
 7:   1  NA      f_2     z
 8:   2   6      f_2     a
 9:   3   7      f_2     x
10:   4   8      f_2     c
11:   5   9      f_2     x
12:  NA  10      f_2     x
> 
> # preserves attribute when types are identical, ex: Date
> melt(DT, id=3:4, measure=c("d_1", "d_2"))
    f_1 f_2 variable      value
 1:   c   z      d_1 2013-09-02
 2:   b   a      d_1 2013-09-03
 3:   a   x      d_1 2013-09-04
 4:   b   c      d_1       <NA>
 5:   b   x      d_1 2013-09-05
 6:   b   x      d_1 2013-09-06
 7:   c   z      d_2 2012-01-07
 8:   b   a      d_2 2012-01-06
 9:   a   x      d_2 2012-01-05
10:   b   c      d_2 2012-01-04
11:   b   x      d_2 2012-01-03
12:   b   x      d_2 2012-01-02
> melt(DT, id=3:4, measure=c("i_1", "d_1")) # attribute not preserved
Warning in melt.data.table(DT, id = 3:4, measure = c("i_1", "d_1")) :
  'measure.vars' [i_1, d_1] are not all of the same type. By order of hierarchy, the molten data value column will be of type 'double'. All measure variables not of type 'double' will be coerced too. Check DETAILS in ?melt.data.table for more on coercion.
    f_1 f_2 variable value
 1:   c   z      i_1     1
 2:   b   a      i_1     2
 3:   a   x      i_1     3
 4:   b   c      i_1     4
 5:   b   x      i_1     5
 6:   b   x      i_1    NA
 7:   c   z      d_1 15950
 8:   b   a      d_1 15951
 9:   a   x      d_1 15952
10:   b   c      d_1    NA
11:   b   x      d_1 15953
12:   b   x      d_1 15954
> 
> # on list
> melt(DT, id=1, measure=c("l_1", "l_2")) # value is a list
    i_1 variable       value
 1:   1      l_1         1,1
 2:   2      l_1       2,2,2
 3:   3      l_1       3,3,3
 4:   4      l_1       4,4,4
 5:   5      l_1   5,5,5,5,5
 6:  NA      l_1          NA
 7:   1      l_2       a,a,a
 8:   2      l_2         c,c
 9:   3      l_2           a
10:   4      l_2         a,a
11:   5      l_2       b,b,b
12:  NA      l_2 NA,NA,NA,NA
> melt(DT, id=1, measure=c("c_1", "l_1")) # c1 coerced to list
Warning in melt.data.table(DT, id = 1, measure = c("c_1", "l_1")) :
  'measure.vars' [c_1, l_1] are not all of the same type. By order of hierarchy, the molten data value column will be of type 'list'. All measure variables not of type 'list' will be coerced too. Check DETAILS in ?melt.data.table for more on coercion.
    i_1 variable     value
 1:   1      c_1         a
 2:   2      c_1         c
 3:   3      c_1         a
 4:   4      c_1         a
 5:   5      c_1         b
 6:  NA      c_1        NA
 7:   1      l_1       1,1
 8:   2      l_1     2,2,2
 9:   3      l_1     3,3,3
10:   4      l_1     4,4,4
11:   5      l_1 5,5,5,5,5
12:  NA      l_1        NA
> 
> # on character
> melt(DT, id=1, measure=c("c_1", "f_1")) # value is char
    i_1 variable value
 1:   1      c_1     a
 2:   2      c_1     c
 3:   3      c_1     a
 4:   4      c_1     a
 5:   5      c_1     b
 6:  NA      c_1  <NA>
 7:   1      f_1     c
 8:   2      f_1     b
 9:   3      f_1     a
10:   4      f_1     b
11:   5      f_1     b
12:  NA      f_1     b
> melt(DT, id=1, measure=c("c_1", "i_2")) # i2 coerced to char
Warning in melt.data.table(DT, id = 1, measure = c("c_1", "i_2")) :
  'measure.vars' [c_1, i_2] are not all of the same type. By order of hierarchy, the molten data value column will be of type 'character'. All measure variables not of type 'character' will be coerced too. Check DETAILS in ?melt.data.table for more on coercion.
    i_1 variable value
 1:   1      c_1     a
 2:   2      c_1     c
 3:   3      c_1     a
 4:   4      c_1     a
 5:   5      c_1     b
 6:  NA      c_1  <NA>
 7:   1      i_2  <NA>
 8:   2      i_2     6
 9:   3      i_2     7
10:   4      i_2     8
11:   5      i_2     9
12:  NA      i_2    10
> 
> # on na.rm=TRUE. NAs are removed efficiently, from within C
> melt(DT, id=1, measure=c("c_1", "i_2"), na.rm=TRUE) # remove NA
Warning in melt.data.table(DT, id = 1, measure = c("c_1", "i_2"), na.rm = TRUE) :
  'measure.vars' [c_1, i_2] are not all of the same type. By order of hierarchy, the molten data value column will be of type 'character'. All measure variables not of type 'character' will be coerced too. Check DETAILS in ?melt.data.table for more on coercion.
    i_1 variable value
 1:   1      c_1     a
 2:   2      c_1     c
 3:   3      c_1     a
 4:   4      c_1     a
 5:   5      c_1     b
 6:   2      i_2     6
 7:   3      i_2     7
 8:   4      i_2     8
 9:   5      i_2     9
10:  NA      i_2    10
> 
> # measure.vars can be also a list
> # melt "f_1,f_2" and "d_1,d_2" simultaneously, retain 'factor' attribute
> # convenient way using internal function patterns()
> melt(DT, id=1:2, measure=patterns("^f_", "^d_"), value.factor=TRUE)
    i_1 i_2 variable value1     value2
 1:   1  NA        1      c 2013-09-02
 2:   2   6        1      b 2013-09-03
 3:   3   7        1      a 2013-09-04
 4:   4   8        1      b       <NA>
 5:   5   9        1      b 2013-09-05
 6:  NA  10        1      b 2013-09-06
 7:   1  NA        2      z 2012-01-07
 8:   2   6        2      a 2012-01-06
 9:   3   7        2      x 2012-01-05
10:   4   8        2      c 2012-01-04
11:   5   9        2      x 2012-01-03
12:  NA  10        2      x 2012-01-02
> # same as above, but provide list of columns directly by column names or indices
> melt(DT, id=1:2, measure=list(3:4, c("d_1", "d_2")), value.factor=TRUE)
    i_1 i_2 variable value1     value2
 1:   1  NA        1      c 2013-09-02
 2:   2   6        1      b 2013-09-03
 3:   3   7        1      a 2013-09-04
 4:   4   8        1      b       <NA>
 5:   5   9        1      b 2013-09-05
 6:  NA  10        1      b 2013-09-06
 7:   1  NA        2      z 2012-01-07
 8:   2   6        2      a 2012-01-06
 9:   3   7        2      x 2012-01-05
10:   4   8        2      c 2012-01-04
11:   5   9        2      x 2012-01-03
12:  NA  10        2      x 2012-01-02
> # same as above, but provide names directly:
> melt(DT, id=1:2, measure=patterns(f="^f_", d="^d_"), value.factor=TRUE)
    i_1 i_2 variable f          d
 1:   1  NA        1 c 2013-09-02
 2:   2   6        1 b 2013-09-03
 3:   3   7        1 a 2013-09-04
 4:   4   8        1 b       <NA>
 5:   5   9        1 b 2013-09-05
 6:  NA  10        1 b 2013-09-06
 7:   1  NA        2 z 2012-01-07
 8:   2   6        2 a 2012-01-06
 9:   3   7        2 x 2012-01-05
10:   4   8        2 c 2012-01-04
11:   5   9        2 x 2012-01-03
12:  NA  10        2 x 2012-01-02
> 
> # na.rm=TRUE removes rows with NAs in any 'value' columns
> melt(DT, id=1:2, measure=patterns("f_", "d_"), value.factor=TRUE, na.rm=TRUE)
    i_1 i_2 variable value1     value2
 1:   1  NA        1      c 2013-09-02
 2:   2   6        1      b 2013-09-03
 3:   3   7        1      a 2013-09-04
 4:   5   9        1      b 2013-09-05
 5:  NA  10        1      b 2013-09-06
 6:   1  NA        2      z 2012-01-07
 7:   2   6        2      a 2012-01-06
 8:   3   7        2      x 2012-01-05
 9:   4   8        2      c 2012-01-04
10:   5   9        2      x 2012-01-03
11:  NA  10        2      x 2012-01-02
> 
> # return 'NA' for missing columns, 'na.rm=TRUE' ignored due to list column
> melt(DT, id=1:2, measure=patterns("l_", "c_"), na.rm=TRUE)
    i_1 i_2 variable      value1 value2
 1:   1  NA        1         1,1      a
 2:   2   6        1       2,2,2      c
 3:   3   7        1       3,3,3      a
 4:   4   8        1       4,4,4      a
 5:   5   9        1   5,5,5,5,5      b
 6:  NA  10        1          NA   <NA>
 7:   1  NA        2       a,a,a   <NA>
 8:   2   6        2         c,c   <NA>
 9:   3   7        2           a   <NA>
10:   4   8        2         a,a   <NA>
11:   5   9        2       b,b,b   <NA>
12:  NA  10        2 NA,NA,NA,NA   <NA>
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("melt.data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("merge")
> ### * merge
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: merge
> ### Title: Merge two data.tables
> ### Aliases: merge merge.data.table
> ### Keywords: data
> 
> ### ** Examples
> 
> (dt1 <- data.table(A = letters[1:10], X = 1:10, key = "A"))
    A  X
 1: a  1
 2: b  2
 3: c  3
 4: d  4
 5: e  5
 6: f  6
 7: g  7
 8: h  8
 9: i  9
10: j 10
> (dt2 <- data.table(A = letters[5:14], Y = 1:10, key = "A"))
    A  Y
 1: e  1
 2: f  2
 3: g  3
 4: h  4
 5: i  5
 6: j  6
 7: k  7
 8: l  8
 9: m  9
10: n 10
> merge(dt1, dt2)
   A  X Y
1: e  5 1
2: f  6 2
3: g  7 3
4: h  8 4
5: i  9 5
6: j 10 6
> merge(dt1, dt2, all = TRUE)
    A  X  Y
 1: a  1 NA
 2: b  2 NA
 3: c  3 NA
 4: d  4 NA
 5: e  5  1
 6: f  6  2
 7: g  7  3
 8: h  8  4
 9: i  9  5
10: j 10  6
11: k NA  7
12: l NA  8
13: m NA  9
14: n NA 10
> 
> (dt1 <- data.table(A = letters[rep(1:3, 2)], X = 1:6, key = "A"))
   A X
1: a 1
2: a 4
3: b 2
4: b 5
5: c 3
6: c 6
> (dt2 <- data.table(A = letters[rep(2:4, 2)], Y = 6:1, key = "A"))
   A Y
1: b 6
2: b 3
3: c 5
4: c 2
5: d 4
6: d 1
> merge(dt1, dt2, allow.cartesian=TRUE)
   A X Y
1: b 2 6
2: b 2 3
3: b 5 6
4: b 5 3
5: c 3 5
6: c 3 2
7: c 6 5
8: c 6 2
> 
> (dt1 <- data.table(A = c(rep(1L, 5), 2L), B = letters[rep(1:3, 2)], X = 1:6, key = "A,B"))
   A B X
1: 1 a 1
2: 1 a 4
3: 1 b 2
4: 1 b 5
5: 1 c 3
6: 2 c 6
> (dt2 <- data.table(A = c(rep(1L, 5), 2L), B = letters[rep(2:4, 2)], Y = 6:1, key = "A,B"))
   A B Y
1: 1 b 6
2: 1 b 3
3: 1 c 5
4: 1 c 2
5: 1 d 4
6: 2 d 1
> merge(dt1, dt2)
   A B X Y
1: 1 b 2 6
2: 1 b 2 3
3: 1 b 5 6
4: 1 b 5 3
5: 1 c 3 5
6: 1 c 3 2
> merge(dt1, dt2, by="B", allow.cartesian=TRUE)
   B A.x X A.y Y
1: b   1 2   1 6
2: b   1 2   1 3
3: b   1 5   1 6
4: b   1 5   1 3
5: c   1 3   1 5
6: c   1 3   1 2
7: c   2 6   1 5
8: c   2 6   1 2
> 
> # test it more:
> d1 <- data.table(a=rep(1:2,each=3), b=1:6, key="a,b")
> d2 <- data.table(a=0:1, bb=10:11, key="a")
> d3 <- data.table(a=0:1, key="a")
> d4 <- data.table(a=0:1, b=0:1, key="a,b")
> 
> merge(d1, d2)
   a b bb
1: 1 1 11
2: 1 2 11
3: 1 3 11
> merge(d2, d1)
   a bb b
1: 1 11 1
2: 1 11 2
3: 1 11 3
> merge(d1, d2, all=TRUE)
   a  b bb
1: 0 NA 10
2: 1  1 11
3: 1  2 11
4: 1  3 11
5: 2  4 NA
6: 2  5 NA
7: 2  6 NA
> merge(d2, d1, all=TRUE)
   a bb  b
1: 0 10 NA
2: 1 11  1
3: 1 11  2
4: 1 11  3
5: 2 NA  4
6: 2 NA  5
7: 2 NA  6
> 
> merge(d3, d1)
   a b
1: 1 1
2: 1 2
3: 1 3
> merge(d1, d3)
   a b
1: 1 1
2: 1 2
3: 1 3
> merge(d1, d3, all=TRUE)
   a  b
1: 0 NA
2: 1  1
3: 1  2
4: 1  3
5: 2  4
6: 2  5
7: 2  6
> merge(d3, d1, all=TRUE)
   a  b
1: 0 NA
2: 1  1
3: 1  2
4: 1  3
5: 2  4
6: 2  5
7: 2  6
> 
> merge(d1, d4)
   a b
1: 1 1
> merge(d1, d4, by="a", suffixes=c(".d1", ".d4"))
   a b.d1 b.d4
1: 1    1    1
2: 1    2    1
3: 1    3    1
> merge(d4, d1)
   a b
1: 1 1
> merge(d1, d4, all=TRUE)
   a b
1: 0 0
2: 1 1
3: 1 2
4: 1 3
5: 2 4
6: 2 5
7: 2 6
> merge(d4, d1, all=TRUE)
   a b
1: 0 0
2: 1 1
3: 1 2
4: 1 3
5: 2 4
6: 2 5
7: 2 6
> 
> # new feature, no need to set keys anymore
> set.seed(1L)
> d1 <- data.table(a=sample(rep(1:3,each=2)), z=1:6)
> d2 <- data.table(a=2:0, z=10:12)
> merge(d1, d2, by="a")
   a z.x z.y
1: 1   1  11
2: 1   5  11
3: 2   3  10
4: 2   4  10
> merge(d1, d2, by="a", all=TRUE)
   a z.x z.y
1: 0  NA  12
2: 1   1  11
3: 1   5  11
4: 2   3  10
5: 2   4  10
6: 3   2  NA
7: 3   6  NA
> 
> # new feature, using by.x and by.y arguments
> setnames(d2, "a", "b")
> merge(d1, d2, by.x="a", by.y="b")
   a z.x z.y
1: 1   1  11
2: 1   5  11
3: 2   3  10
4: 2   4  10
> merge(d1, d2, by.x="a", by.y="b", all=TRUE)
   a z.x z.y
1: 0  NA  12
2: 1   1  11
3: 1   5  11
4: 2   3  10
5: 2   4  10
6: 3   2  NA
7: 3   6  NA
> merge(d2, d1, by.x="b", by.y="a")
   b z.x z.y
1: 1  11   1
2: 1  11   5
3: 2  10   3
4: 2  10   4
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("merge", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("na.omit.data.table")
> ### * na.omit.data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: na.omit.data.table
> ### Title: Remove rows with missing values on columns specified
> ### Aliases: na.omit.data.table na.omit
> ### Keywords: data
> 
> ### ** Examples
> 
> DT = data.table(x=c(1,NaN,NA,3), y=c(NA_integer_, 1:3), z=c("a", NA_character_, "b", "c"))
> # default behaviour
> na.omit(DT)
   x y z
1: 3 3 c
> # omit rows where 'x' has a missing value
> na.omit(DT, cols="x")
   x  y z
1: 1 NA a
2: 3  3 c
> # omit rows where either 'x' or 'y' have missing values
> na.omit(DT, cols=c("x", "y"))
   x y z
1: 3 3 c
> 
> ## Not run: 
> ##D # Timings on relatively large data
> ##D set.seed(1L)
> ##D DT = data.table(x = sample(c(1:100, NA_integer_), 5e7L, TRUE),
> ##D                 y = sample(c(rnorm(100), NA), 5e7L, TRUE))
> ##D system.time(ans1 <- na.omit(DT)) ## 2.6 seconds
> ##D system.time(ans2 <- stats:::na.omit.data.frame(DT)) ## 29 seconds
> ##D # identical? check each column separately, as ans2 will have additional attribute
> ##D all(sapply(1:2, function(i) identical(ans1[[i]], ans2[[i]]))) ## TRUE
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("na.omit.data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("patterns")
> ### * patterns
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: patterns
> ### Title: Obtain matching indices corresponding to patterns
> ### Aliases: patterns
> ### Keywords: data
> 
> ### ** Examples
> 
> DT = data.table(x1 = 1:5, x2 = 6:10, y1 = letters[1:5], y2 = letters[6:10])
> # melt all columns that begin with 'x' & 'y', respectively, into separate columns
> melt(DT, measure.vars = patterns("^x", "^y", cols=names(DT)))
    variable value1 value2
 1:        1      1      a
 2:        1      2      b
 3:        1      3      c
 4:        1      4      d
 5:        1      5      e
 6:        2      6      f
 7:        2      7      g
 8:        2      8      h
 9:        2      9      i
10:        2     10      j
> # when used with melt, 'cols' is implictly assumed to be names of input
> # data.table, if not provided.
> melt(DT, measure.vars = patterns("^x", "^y"))
    variable value1 value2
 1:        1      1      a
 2:        1      2      b
 3:        1      3      c
 4:        1      4      d
 5:        1      5      e
 6:        2      6      f
 7:        2      7      g
 8:        2      8      h
 9:        2      9      i
10:        2     10      j
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("patterns", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("print.data.table")
> ### * print.data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: print.data.table
> ### Title: data.table Printing Options
> ### Aliases: print.data.table
> 
> ### ** Examples
> 
>   #output compression
>   DT <- data.table(a = 1:1000)
>   print(DT, nrows = 100, topn = 4)
         a
   1:    1
   2:    2
   3:    3
   4:    4
  ---     
 997:  997
 998:  998
 999:  999
1000: 1000
> 
>   #`quote` can be used to identify whitespace
>   DT <- data.table(blanks = c(" 12", " 34"),
+                    noblanks = c("12", "34"))
>   print(DT, quote = TRUE)
   "blanks" "noblanks"
1:    " 12"       "12"
2:    " 34"       "34"
> 
>   #`class` provides handy column type summaries at a glance
>   DT <- data.table(a = vector("integer", 3),
+                    b = vector("complex", 3),
+                    c = as.IDate(paste0("2016-02-0", 1:3)))
>   print(DT, class = TRUE)
       a      b          c
   <int> <cplx>     <IDat>
1:     0   0+0i 2016-02-01
2:     0   0+0i 2016-02-02
3:     0   0+0i 2016-02-03
> 
>   #`row.names` can be eliminated to save space
>   DT <- data.table(a = 1:3)
>   print(DT, row.names = FALSE)
 a
 1
 2
 3
> 
>   #`print.keys` can alert which columns are currently keys
>   DT <- data.table(a=1:3, b=4:6, c=7:9, key="b,a")
>   setindexv(DT, c("a", "b"))
>   setindexv(DT, "a")
>   print(DT, print.keys=TRUE)
Key: <b, a>
Indices: <a__b>, <a>
   a b c
1: 1 4 7
2: 2 5 8
3: 3 6 9
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("print.data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("rbindlist")
> ### * rbindlist
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: rbindlist
> ### Title: Makes one data.table from a list of many
> ### Aliases: rbindlist rbind.data.table rbind
> ### Keywords: data
> 
> ### ** Examples
> 
> # default case
> DT1 = data.table(A=1:3,B=letters[1:3])
> DT2 = data.table(A=4:5,B=letters[4:5])
> l = list(DT1,DT2)
> rbindlist(l)
   A B
1: 1 a
2: 2 b
3: 3 c
4: 4 d
5: 5 e
> 
> # bind correctly by names
> DT1 = data.table(A=1:3,B=letters[1:3])
> DT2 = data.table(B=letters[4:5],A=4:5)
> l = list(DT1,DT2)
> rbindlist(l, use.names=TRUE)
   A B
1: 1 a
2: 2 b
3: 3 c
4: 4 d
5: 5 e
> 
> # fill missing columns, and match by col names
> DT1 = data.table(A=1:3,B=letters[1:3])
> DT2 = data.table(B=letters[4:5],C=factor(1:2))
> l = list(DT1,DT2)
> rbindlist(l, use.names=TRUE, fill=TRUE)
    A B    C
1:  1 a <NA>
2:  2 b <NA>
3:  3 c <NA>
4: NA d    1
5: NA e    2
> 
> # generate index column, auto generates indices
> rbindlist(l, use.names=TRUE, fill=TRUE, idcol=TRUE)
   .id  A B    C
1:   1  1 a <NA>
2:   1  2 b <NA>
3:   1  3 c <NA>
4:   2 NA d    1
5:   2 NA e    2
> # let's name the list
> setattr(l, 'names', c("a", "b"))
> rbindlist(l, use.names=TRUE, fill=TRUE, idcol="ID")
   ID  A B    C
1:  a  1 a <NA>
2:  a  2 b <NA>
3:  a  3 c <NA>
4:  b NA d    1
5:  b NA e    2
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("rbindlist", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("rleid")
> ### * rleid
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: rleid
> ### Title: Generate run-length type group id
> ### Aliases: rleid rleidv
> ### Keywords: data
> 
> ### ** Examples
> 
> DT = data.table(grp=rep(c("A", "B", "C", "A", "B"), c(2,2,3,1,2)), value=1:10)
> rleid(DT$grp) # get run-length ids
 [1] 1 1 2 2 3 3 3 4 5 5
> rleidv(DT, "grp") # same as above
 [1] 1 1 2 2 3 3 3 4 5 5
> 
> rleid(DT$grp, prefix="grp") # prefix with 'grp'
 [1] "grp1" "grp1" "grp2" "grp2" "grp3" "grp3" "grp3" "grp4" "grp5" "grp5"
> 
> # get sum of value over run-length groups
> DT[, sum(value), by=.(grp, rleid(grp))]
   grp rleid V1
1:   A     1  3
2:   B     2  7
3:   C     3 18
4:   A     4  8
5:   B     5 19
> DT[, sum(value), by=.(grp, rleid(grp, prefix="grp"))]
   grp rleid V1
1:   A  grp1  3
2:   B  grp2  7
3:   C  grp3 18
4:   A  grp4  8
5:   B  grp5 19
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("rleid", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("rowid")
> ### * rowid
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: rowid
> ### Title: Generate unique row ids within each group
> ### Aliases: rowid rowidv
> ### Keywords: data
> 
> ### ** Examples
> 
> DT = data.table(x=c(20,10,10,30,30,20), y=c("a", "a", "a", "b", "b", "b"), z=1:6)
> 
> rowid(DT$x) # 1,1,2,1,2,2
[1] 1 1 2 1 2 2
> rowidv(DT, cols="x") # same as above
[1] 1 1 2 1 2 2
> 
> rowid(DT$x, prefix="group") # prefixed with 'group'
[1] "group1" "group1" "group2" "group1" "group2" "group2"
> 
> rowid(DT$x, DT$y) # 1,1,2,1,2,1
[1] 1 1 2 1 2 1
> rowidv(DT, cols=c("x","y")) # same as above
[1] 1 1 2 1 2 1
> DT[, .(N=seq_len(.N)), by=.(x,y)]$N # same as above
[1] 1 1 2 1 2 1
> 
> # convenient usage with dcast
> dcast(DT, x ~ rowid(x, prefix="group"), value.var="z")
    x group1 group2
1: 10      2      3
2: 20      1      6
3: 30      4      5
> #     x group1 group2
> # 1: 10      2      3
> # 2: 20      1      6
> # 3: 30      4      5
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("rowid", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("setDF")
> ### * setDF
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: setDF
> ### Title: Coerce a data.table to data.frame by reference
> ### Aliases: setDF
> ### Keywords: data
> 
> ### ** Examples
> 
> X = data.table(x=1:5, y=6:10)
> ## convert 'X' to data.frame, without any copy.
> setDF(X)
> 
> X = data.table(x=1:5, y=6:10)
> ## idem, assigning row names
> setDF(X, rownames = LETTERS[1:5])
> 
> X = list(x=1:5, y=6:10)
> # X is converted to a data.frame without any copy.
> setDF(X)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("setDF", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("setDT")
> ### * setDT
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: setDT
> ### Title: Coerce lists and data.frames to data.table by reference
> ### Aliases: setDT
> ### Keywords: data
> 
> ### ** Examples
> 
> 
> set.seed(45L)
> X = data.frame(A=sample(3, 10, TRUE),
+          B=sample(letters[1:3], 10, TRUE),
+          C=sample(10), stringsAsFactors=FALSE)
> 
> # Convert X to data.table by reference and
> # get the frequency of each "A,B" combination
> setDT(X)[, .N, by=.(A,B)]
   A B N
1: 2 b 3
2: 1 c 2
3: 1 a 2
4: 1 b 2
5: 2 a 1
> 
> # convert list to data.table
> # autofill names
> X = list(1:4, letters[1:4])
> setDT(X)
> # don't provide names
> X = list(a=1:4, letters[1:4])
> setDT(X, FALSE)
> 
> # setkey directly
> X = list(a = 4:1, b=runif(4))
> setDT(X, key="a")[]
   a         b
1: 1 0.8476840
2: 2 0.4855804
3: 3 0.3256450
4: 4 0.3924327
> 
> # check.names argument
> X = list(a=1:5, a=6:10)
> setDT(X, check.names=TRUE)[]
   a a.1
1: 1   6
2: 2   7
3: 3   8
4: 4   9
5: 5  10
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("setDT", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("setNumericRounding")
> ### * setNumericRounding
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: setNumericRounding
> ### Title: Change or turn off numeric rounding
> ### Aliases: setNumericRounding getNumericRounding
> ### Keywords: data
> 
> ### ** Examples
> 
> DT = data.table(a=seq(0,1,by=0.2),b=1:2, key="a")
> DT
     a b
1: 0.0 1
2: 0.2 2
3: 0.4 1
4: 0.6 2
5: 0.8 1
6: 1.0 2
> setNumericRounding(0)   # By default, rounding is turned off
> DT[.(0.4)]   # works
     a b
1: 0.4 1
> DT[.(0.6)]   # no match, can be confusing since 0.6 is clearly there in DT
     a  b
1: 0.6 NA
>              # happens due to floating point representation limitations
> 
> setNumericRounding(2)   # round off last 2 bytes
> DT[.(0.6)]   # works
     a b
1: 0.6 2
> 
> # using type 'numeric' for integers > 2^31 (typically ids)
> DT = data.table(id = c(1234567890123, 1234567890124, 1234567890125), val=1:3)
> print(DT, digits=15)
              id val
1: 1234567890123   1
2: 1234567890124   2
3: 1234567890125   3
> DT[,.N,by=id]   # 1 row, (last 2 bytes rounded)
             id N
1: 1.234568e+12 3
> setNumericRounding(0)
> DT[,.N,by=id]   # 3 rows, (no rounding, default)
             id N
1: 1.234568e+12 1
2: 1.234568e+12 1
3: 1.234568e+12 1
> # better to use bit64::integer64 for such ids
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("setNumericRounding", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("setattr")
> ### * setattr
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: setattr
> ### Title: Set attributes of objects by reference
> ### Aliases: setattr setnames
> ### Keywords: data
> 
> ### ** Examples
> 
> 
> DT <- data.table(a = 1, b = 2, d = 3)
> 
> old <- c("a", "b", "c", "d")
> new <- c("A", "B", "C", "D")
> 
> setnames(DT, old, new, skip_absent = TRUE) # skips old[3] because "c" is not a column name of DT
> 
> DF = data.frame(a=1:2,b=3:4)       # base data.frame to demo copies and syntax
> if (capabilities()["profmem"])     # usually memory profiling is available but just in case
+   tracemem(DF)
Warning in doTryCatch(return(expr), name, parentenv, handler) :
  unable to load shared object '/Library/Frameworks/R.framework/Resources/modules//R_X11.so':
  dlopen(/Library/Frameworks/R.framework/Resources/modules//R_X11.so, 6): Library not loaded: /opt/X11/lib/libSM.6.dylib
  Referenced from: /Library/Frameworks/R.framework/Resources/modules//R_X11.so
  Reason: image not found
[1] "<0x7fc544f31648>"
> colnames(DF)[1] <- "A"             # 4 shallow copies (R >= 3.1, was 4 deep copies before)
tracemem[0x7fc544f31648 -> 0x7fc544f31ac8]: 
tracemem[0x7fc544f31ac8 -> 0x7fc544f31b48]: 
tracemem[0x7fc544f31b48 -> 0x7fc544f31b88]: colnames<- 
tracemem[0x7fc544f31b88 -> 0x7fc544f31bc8]: colnames<- 
> names(DF)[1] <- "A"                # 3 shallow copies
tracemem[0x7fc544f31bc8 -> 0x7fc544f31c08]: 
tracemem[0x7fc544f31c08 -> 0x7fc544f31c88]: 
tracemem[0x7fc544f31c88 -> 0x7fc544f31cc8]: 
> names(DF) <- c("A", "b")           # 1 shallow copy
tracemem[0x7fc544f31cc8 -> 0x7fc544f31d48]: 
> `names<-`(DF,c("A","b"))           # 1 shallow copy
tracemem[0x7fc544f31d48 -> 0x7fc544f31dc8]: 
  A b
1 1 3
2 2 4
> 
> DT = data.table(a=1:2,b=3:4,c=5:6) # compare to data.table
> if (capabilities()["profmem"])
+   tracemem(DT)                     # by reference, no deep or shallow copies
[1] "<0x7fc5482bfa00>"
> setnames(DT,"b","B")               # by name, no match() needed (warning if "b" is missing)
> setnames(DT,3,"C")                 # by position with warning if 3 > ncol(DT)
> setnames(DT,2:3,c("D","E"))        # multiple
> setnames(DT,c("a","E"),c("A","F")) # multiple by name (warning if either "a" or "E" is missing)
> setnames(DT,c("X","Y","Z"))        # replace all (length of names must be == ncol(DT))
> 
> DT <- data.table(x = 1:3, y = 4:6, z = 7:9)
> setnames(DT, -2, c("a", "b"))      # NEW FR #1443, allows -ve indices in 'old' argument
> 
> DT = data.table(a=1:3, b=4:6)
> f = function(...) {
+     # ...
+     setattr(DT,"myFlag",TRUE)  # by reference
+     # ...
+     localDT = copy(DT)
+     setattr(localDT,"myFlag2",TRUE)
+     # ...
+     invisible()
+ }
> f()
> attr(DT,"myFlag")   # TRUE
[1] TRUE
> attr(DT,"myFlag2")  # NULL
NULL
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("setattr", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("setcolorder")
> ### * setcolorder
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: setcolorder
> ### Title: Fast column reordering of a data.table by reference
> ### Aliases: setcolorder
> ### Keywords: data
> 
> ### ** Examples
> 
> 
> set.seed(45L)
> DT = data.table(A=sample(3, 10, TRUE),
+          B=sample(letters[1:3], 10, TRUE), C=sample(10))
> 
> setcolorder(DT, c("C", "A", "B"))
> 
> #incomplete specification
> setcolorder(DT, "A")
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("setcolorder", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("setkey")
> ### * setkey
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: setkey
> ### Title: Create key on a data table
> ### Aliases: setkey setkeyv key key<- haskey set2key set2keyv setindex
> ###   setindexv key2 indices
> ### Keywords: data
> 
> ### ** Examples
> 
> # Type 'example(setkey)' to run these at prompt and browse output
> 
> DT = data.table(A=5:1,B=letters[5:1])
> DT # before
   A B
1: 5 e
2: 4 d
3: 3 c
4: 2 b
5: 1 a
> setkey(DT,B)          # re-orders table and marks it sorted.
> DT # after
   A B
1: 1 a
2: 2 b
3: 3 c
4: 4 d
5: 5 e
> tables()              # KEY column reports the key'd columns
   NAME NROW NCOL MB COLS KEY
1:   DT    5    2  0  A,B   B
Total: 0MB
> key(DT)
[1] "B"
> keycols = c("A","B")
> setkeyv(DT,keycols)   # rather than key(DT)<-keycols (which copies entire table)
> 
> DT = data.table(A=5:1,B=letters[5:1])
> DT2 = DT              # does not copy
> setkey(DT2,B)         # does not copy-on-write to DT2
> identical(DT,DT2)     # TRUE. DT and DT2 are two names for the same keyed table
[1] TRUE
> 
> DT = data.table(A=5:1,B=letters[5:1])
> DT2 = copy(DT)        # explicit copy() needed to copy a data.table
> setkey(DT2,B)         # now just changes DT2
> identical(DT,DT2)     # FALSE. DT and DT2 are now different tables
[1] FALSE
> 
> DT = data.table(A=5:1,B=letters[5:1])
> setindex(DT)          # set indices
> setindex(DT, A)
> setindex(DT, B)
> indices(DT)           # get indices single vector
[1] "A__B" "A"    "B"   
> indices(DT, vectors = TRUE) # get indices list
[[1]]
[1] "A" "B"

[[2]]
[1] "A"

[[3]]
[1] "B"

> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("setkey", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("setops")
> ### * setops
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: setops
> ### Title: Set operations for data tables
> ### Aliases: setops intersect fintersect setdiff fsetdiff except fexcept
> ###   union funion setequal fsetequal
> ### Keywords: data
> 
> ### ** Examples
> 
> x = data.table(c(1,2,2,2,3,4,4))
> x2 = data.table(c(1,2,3,4)) # same set of rows as x
> y = data.table(c(2,3,4,4,4,5))
> fintersect(x, y)            # intersect
   V1
1:  2
2:  3
3:  4
> fintersect(x, y, all=TRUE)  # intersect all
   V1
1:  2
2:  3
3:  4
4:  4
> fsetdiff(x, y)              # except
   V1
1:  1
> fsetdiff(x, y, all=TRUE)    # except all
   V1
1:  1
2:  2
3:  2
> funion(x, y)                # union
   V1
1:  1
2:  2
3:  3
4:  4
5:  5
> funion(x, y, all=TRUE)      # union all
    V1
 1:  1
 2:  2
 3:  2
 4:  2
 5:  3
 6:  4
 7:  4
 8:  2
 9:  3
10:  4
11:  4
12:  4
13:  5
> fsetequal(x, x2, all=FALSE) # setequal
[1] TRUE
> fsetequal(x, x2)            # setequal all
[1] FALSE
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("setops", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("setorder")
> ### * setorder
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: setorder
> ### Title: Fast row reordering of a data.table by reference
> ### Aliases: setorder setorderv order fastorder forder
> ### Keywords: data
> 
> ### ** Examples
> 
> 
> set.seed(45L)
> DT = data.table(A=sample(3, 10, TRUE),
+          B=sample(letters[1:3], 10, TRUE), C=sample(10))
> 
> # setorder
> setorder(DT, A, -B)
> 
> # same as above, but using setorderv
> setorderv(DT, c("A", "B"), c(1, -1))
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("setorder", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("shift")
> ### * shift
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: shift
> ### Title: Fast lead/lag for vectors and lists
> ### Aliases: shift lead lag
> ### Keywords: data
> 
> ### ** Examples
> 
> # on vectors, returns a vector as long as length(n) == 1, #1127
> x = 1:5
> # lag with n=1 and pad with NA (returns vector)
> shift(x, n=1, fill=NA, type="lag")
[1] NA  1  2  3  4
> # lag with n=1 and 2, and pad with 0 (returns list)
> shift(x, n=1:2, fill=0, type="lag")
[[1]]
[1] 0 1 2 3 4

[[2]]
[1] 0 0 1 2 3

> # getting a window by using positive and negative n:
> shift(x, n = -1:1)
[[1]]
[1]  2  3  4  5 NA

[[2]]
[1] 1 2 3 4 5

[[3]]
[1] NA  1  2  3  4

> shift(x, n = -1:1, type = "shift", give.names = TRUE)
$`x_shift_-1`
[1]  2  3  4  5 NA

$x_shift_0
[1] 1 2 3 4 5

$x_shift_1
[1] NA  1  2  3  4

> 
> # on data.tables
> DT = data.table(year=2010:2014, v1=runif(5), v2=1:5, v3=letters[1:5])
> # lag columns 'v1,v2,v3' DT by 1 and fill with 0
> cols = c("v1","v2","v3")
> anscols = paste("lead", cols, sep="_")
> DT[, (anscols) := shift(.SD, 1, 0, "lead"), .SDcols=cols]
> 
> # return a new data.table instead of updating
> # with names automatically set
> DT = data.table(year=2010:2014, v1=runif(5), v2=1:5, v3=letters[1:5])
> DT[, shift(.SD, 1:2, NA, "lead", TRUE), .SDcols=2:4]
    v1_lead_1  v1_lead_2 v2_lead_1 v2_lead_2 v3_lead_1 v3_lead_2
1: 0.94467527 0.66079779         2         3         b         c
2: 0.66079779 0.62911404         3         4         c         d
3: 0.62911404 0.06178627         4         5         d         e
4: 0.06178627         NA         5        NA         e      <NA>
5:         NA         NA        NA        NA      <NA>      <NA>
> 
> # lag/lead in the right order
> DT = data.table(year=2010:2014, v1=runif(5), v2=1:5, v3=letters[1:5])
> DT = DT[sample(nrow(DT))]
> # add lag=1 for columns 'v1,v2,v3' in increasing order of 'year'
> cols = c("v1","v2","v3")
> anscols = paste("lag", cols, sep="_")
> DT[order(year), (cols) := shift(.SD, 1, type="lag"), .SDcols=cols]
> DT[order(year)]
   year        v1 v2   v3
1: 2010        NA NA <NA>
2: 2011 0.2059746  1    a
3: 2012 0.1765568  2    b
4: 2013 0.6870228  3    c
5: 2014 0.3841037  4    d
> 
> # while grouping
> DT = data.table(year=rep(2010:2011, each=3), v1=1:6)
> DT[, c("lag1", "lag2") := shift(.SD, 1:2), by=year]
> 
> # on lists
> ll = list(1:3, letters[4:1], runif(2))
> shift(ll, 1, type="lead")
[[1]]
[1]  2  3 NA

[[2]]
[1] "c" "b" "a" NA 

[[3]]
[1] 0.2121425        NA

> shift(ll, 1, type="lead", give.names=TRUE)
$V1_lead_1
[1]  2  3 NA

$V2_lead_1
[1] "c" "b" "a" NA 

$V3_lead_1
[1] 0.2121425        NA

> shift(ll, 1:2, type="lead")
[[1]]
[1]  2  3 NA

[[2]]
[1]  3 NA NA

[[3]]
[1] "c" "b" "a" NA 

[[4]]
[1] "b" "a" NA  NA 

[[5]]
[1] 0.2121425        NA

[[6]]
[1] NA NA

> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("shift", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("special-symbols")
> ### * special-symbols
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: special-symbols
> ### Title: Special symbols
> ### Aliases: special-symbols datatable-symbols .SD .I .GRP .BY .N
> ### Keywords: data
> 
> ### ** Examples
> 
> ## Not run: 
> ##D DT = data.table(x=rep(c("b","a","c"),each=3), v=c(1,1,1,2,2,1,1,2,2), y=c(1,3,6), a=1:9, b=9:1)
> ##D DT
> ##D X = data.table(x=c("c","b"), v=8:7, foo=c(4,2))
> ##D X
> ##D 
> ##D DT[.N]                                 # last row, only special symbol allowed in 'i'
> ##D DT[, .N]                               # total number of rows in DT
> ##D DT[, .N, by=x]                         # number of rows in each group
> ##D DT[, .SD, .SDcols=x:y]                 # select columns 'x' and 'y'
> ##D DT[, .SD[1]]                           # first row of all columns
> ##D DT[, .SD[1], by=x]                     # first row of 'y' and 'v' for each group in 'x'
> ##D DT[, c(.N, lapply(.SD, sum)), by=x]    # get rows *and* sum columns 'v' and 'y' by group
> ##D DT[, .I[1], by=x]                      # row number in DT corresponding to each group
> ##D DT[, .N, by=rleid(v)]                  # get count of consecutive runs of 'v'
> ##D DT[, c(.(y=max(y)), lapply(.SD, min)),
> ##D         by=rleid(v), .SDcols=v:b]      # compute 'j' for each consecutive runs of 'v'
> ##D DT[, grp := .GRP, by=x]                # add a group counter
> ##D X[, DT[.BY, y, on="x"], by=x]          # join within each group
> ## End(Not run)
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("special-symbols", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("split")
> ### * split
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: split
> ### Title: Split data.table into chunks in a list
> ### Aliases: split split.data.table
> ### Keywords: data
> 
> ### ** Examples
> 
> set.seed(123)
> DT = data.table(x1 = rep(letters[1:2], 6),
+                 x2 = rep(letters[3:5], 4),
+                 x3 = rep(letters[5:8], 3),
+                 y = rnorm(12))
> DT = DT[sample(.N)]
> DF = as.data.frame(DT)
> 
> # split consistency with data.frame: `x, f, drop`
> all.equal(
+     split(DT, list(DT$x1, DT$x2)),
+     lapply(split(DF, list(DF$x1, DF$x2)), setDT)
+ )
[1] TRUE
> 
> # nested list using `flatten` arguments
> split(DT, by=c("x1", "x2"))
$b.d
   x1 x2 x3          y
1:  b  d  h -1.2650612
2:  b  d  f -0.2301775

$b.e
   x1 x2 x3         y
1:  b  e  h 0.3598138
2:  b  e  f 1.7150650

$b.c
   x1 x2 x3           y
1:  b  c  f -0.44566197
2:  b  c  h  0.07050839

$a.e
   x1 x2 x3          y
1:  a  e  g  1.5587083
2:  a  e  e -0.6868529

$a.d
   x1 x2 x3         y
1:  a  d  e 0.1292877
2:  a  d  g 1.2240818

$a.c
   x1 x2 x3          y
1:  a  c  e -0.5604756
2:  a  c  g  0.4609162

> split(DT, by=c("x1", "x2"), flatten=FALSE)
$b
$b$d
   x1 x2 x3          y
1:  b  d  h -1.2650612
2:  b  d  f -0.2301775

$b$e
   x1 x2 x3         y
1:  b  e  h 0.3598138
2:  b  e  f 1.7150650

$b$c
   x1 x2 x3           y
1:  b  c  f -0.44566197
2:  b  c  h  0.07050839


$a
$a$e
   x1 x2 x3          y
1:  a  e  g  1.5587083
2:  a  e  e -0.6868529

$a$d
   x1 x2 x3         y
1:  a  d  e 0.1292877
2:  a  d  g 1.2240818

$a$c
   x1 x2 x3          y
1:  a  c  e -0.5604756
2:  a  c  g  0.4609162


> 
> # dealing with factors
> fdt = DT[, c(lapply(.SD, as.factor), list(y=y)), .SDcols=x1:x3]
> fdf = as.data.frame(fdt)
> sdf = split(fdf, list(fdf$x1, fdf$x2))
> all.equal(
+     split(fdt, by=c("x1", "x2"), sorted=TRUE),
+     lapply(sdf[sort(names(sdf))], setDT)
+ )
[1] TRUE
> 
> # factors having unused levels, drop FALSE, TRUE
> fdt = DT[, .(x1 = as.factor(c(as.character(x1), "c"))[-13L],
+              x2 = as.factor(c("a", as.character(x2)))[-1L],
+              x3 = as.factor(c("a", as.character(x3), "z"))[c(-1L,-14L)],
+              y = y)]
> fdf = as.data.frame(fdt)
> sdf = split(fdf, list(fdf$x1, fdf$x2))
> all.equal(
+     split(fdt, by=c("x1", "x2"), sorted=TRUE),
+     lapply(sdf[sort(names(sdf))], setDT)
+ )
[1] TRUE
> sdf = split(fdf, list(fdf$x1, fdf$x2), drop=TRUE)
> all.equal(
+     split(fdt, by=c("x1", "x2"), sorted=TRUE, drop=TRUE),
+     lapply(sdf[sort(names(sdf))], setDT)
+ )
[1] TRUE
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("split", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("subset.data.table")
> ### * subset.data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: subset.data.table
> ### Title: Subsetting data.tables
> ### Aliases: subset subset.data.table
> ### Keywords: data
> 
> ### ** Examples
> 
> 
> DT <- data.table(a=sample(c('a', 'b', 'c'), 20, replace=TRUE),
+                  b=sample(c('a', 'b', 'c'), 20, replace=TRUE),
+                  c=sample(20), key=c('a', 'b'))
> 
> sub <- subset(DT, a == 'a')
> all.equal(key(sub), key(DT))
[1] TRUE
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("subset.data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("tables")
> ### * tables
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: tables
> ### Title: Display 'data.table' metadata
> ### Aliases: tables
> ### Keywords: data
> 
> ### ** Examples
> 
> DT = data.table(A=1:10, B=letters[1:10])
> DT2 = data.table(A=1:10000, ColB=10000:1)
> setkey(DT,B)
> tables()
   NAME   NROW NCOL MB   COLS KEY
1:   DT     10    2  0    A,B   B
2:  DT2 10,000    2  0 A,ColB    
Total: 0MB
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("tables", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("test.data.table")
> ### * test.data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: test.data.table
> ### Title: Runs a set of tests.
> ### Aliases: test.data.table
> ### Keywords: data
> 
> ### ** Examples
> 
> ## Not run: 
> ##D   library(data.table)
> ##D   test.data.table()
> ## End(Not run)
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("test.data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("timetaken")
> ### * timetaken
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: timetaken
> ### Title: Pretty print of time taken
> ### Aliases: timetaken
> ### Keywords: data
> 
> ### ** Examples
> 
> started.at=proc.time()
> Sys.sleep(1)
> cat("Finished in",timetaken(started.at),"\n")
Finished in 1.005s elapsed (2.076s cpu) 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("timetaken", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("transform.data.table")
> ### * transform.data.table
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: transform.data.table
> ### Title: Data table utilities
> ### Aliases: transform transform.data.table within within.data.table
> ### Keywords: data
> 
> ### ** Examples
> 
> DT <- data.table(a=rep(1:3, each=2), b=1:6)
> 
> DT2 <- transform(DT, c = a^2)
> DT[, c:=a^2]
> identical(DT,DT2)
[1] TRUE
> 
> DT2 <- within(DT, {
+   b <- rev(b)
+   c <- a*2
+   rm(a)
+ })
> DT[,`:=`(b = rev(b),
+          c = a*2,
+          a = NULL)]
> identical(DT,DT2)
[1] TRUE
> 
> DT$d = ave(DT$b, DT$c, FUN=max)               # copies entire DT, even if it is 10GB in RAM
> DT = DT[, transform(.SD, d=max(b)), by="c"]   # same, but even worse as .SD is copied for each group
> DT[, d:=max(b), by="c"]                       # same result, but much faster, shorter and scales
> 
> # Multiple update by group. Convenient, fast, scales and easy to read.
> DT[, `:=`(minb = min(b),
+           meanb = mean(b),
+           bplusd = sum(b+d)),  by=c%/%5]
> DT
   c b d minb meanb bplusd
1: 2 6 6    3   4.5     38
2: 2 5 6    3   4.5     38
3: 4 4 4    3   4.5     38
4: 4 3 4    3   4.5     38
5: 6 2 2    1   1.5      7
6: 6 1 2    1   1.5      7
> 
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("transform.data.table", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("transpose")
> ### * transpose
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: transpose
> ### Title: Efficient transpose of list
> ### Aliases: transpose
> ### Keywords: data
> 
> ### ** Examples
> 
> ll = list(1:5, 6:8)
> transpose(ll)
[[1]]
[1] 1 6

[[2]]
[1] 2 7

[[3]]
[1] 3 8

[[4]]
[1]  4 NA

[[5]]
[1]  5 NA

> setDT(transpose(ll, fill=0))[]
   V1 V2 V3 V4 V5
1:  1  2  3  4  5
2:  6  7  8  0  0
> 
> DT = data.table(x=1:5, y=6:10)
> transpose(DT)
   V1 V2 V3 V4 V5
1:  1  2  3  4  5
2:  6  7  8  9 10
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("transpose", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("truelength")
> ### * truelength
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: truelength
> ### Title: Over-allocation access
> ### Aliases: truelength alloc.col
> ### Keywords: data
> 
> ### ** Examples
> 
> DT = data.table(a=1:3,b=4:6)
> length(DT)                 # 2 column pointer slots used
[1] 2
> truelength(DT)             # 1026 column pointer slots allocated
[1] 1026
> alloc.col(DT,2048)
   a b
1: 1 4
2: 2 5
3: 3 6
> length(DT)                 # 2 used
[1] 2
> truelength(DT)             # 2050 allocated, 2048 free
[1] 2050
> DT[,c:=7L]                 # add new column by assigning to spare slot
> truelength(DT)-length(DT)  # 2047 slots spare
[1] 2047
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("truelength", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("tstrsplit")
> ### * tstrsplit
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: tstrsplit
> ### Title: strsplit and transpose the resulting list efficiently
> ### Aliases: tstrsplit strsplit
> ### Keywords: data
> 
> ### ** Examples
> 
> x = c("abcde", "ghij", "klmnopq")
> strsplit(x, "", fixed=TRUE)
[[1]]
[1] "a" "b" "c" "d" "e"

[[2]]
[1] "g" "h" "i" "j"

[[3]]
[1] "k" "l" "m" "n" "o" "p" "q"

> tstrsplit(x, "", fixed=TRUE)
[[1]]
[1] "a" "g" "k"

[[2]]
[1] "b" "h" "l"

[[3]]
[1] "c" "i" "m"

[[4]]
[1] "d" "j" "n"

[[5]]
[1] "e" NA  "o"

[[6]]
[1] NA  NA  "p"

[[7]]
[1] NA  NA  "q"

> tstrsplit(x, "", fixed=TRUE, fill="<NA>")
[[1]]
[1] "a" "g" "k"

[[2]]
[1] "b" "h" "l"

[[3]]
[1] "c" "i" "m"

[[4]]
[1] "d" "j" "n"

[[5]]
[1] "e"    "<NA>" "o"   

[[6]]
[1] "<NA>" "<NA>" "p"   

[[7]]
[1] "<NA>" "<NA>" "q"   

> 
> # using keep to return just 1,3,5
> tstrsplit(x, "", fixed=TRUE, keep=c(1,3,5))
[[1]]
[1] "a" "g" "k"

[[2]]
[1] "c" "i" "m"

[[3]]
[1] "e" NA  "o"

> 
> # names argument
> tstrsplit(x, "", fixed=TRUE, keep=c(1,3,5), names=LETTERS[1:3])
$A
[1] "a" "g" "k"

$B
[1] "c" "i" "m"

$C
[1] "e" NA  "o"

> 
> DT = data.table(x=c("A/B", "A", "B"), y=1:3)
> DT[, c("c1") := tstrsplit(x, "/", fixed=TRUE, keep=1L)][]
     x y c1
1: A/B 1  A
2:   A 2  A
3:   B 3  B
> DT[, c("c1", "c2") := tstrsplit(x, "/", fixed=TRUE)][]
     x y c1   c2
1: A/B 1  A    B
2:   A 2  A <NA>
3:   B 3  B <NA>
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("tstrsplit", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> cleanEx()
> nameEx("update.dev.pkg")
> ### * update.dev.pkg
> 
> flush(stderr()); flush(stdout())
> 
> base::assign(".ptime", proc.time(), pos = "CheckExEnv")
> ### Name: update.dev.pkg
> ### Title: Perform update of development version of a package
> ### Aliases: update update.dev.pkg
> ### Keywords: data
> 
> ### ** Examples
> 
>   # data.table::update.dev.pkg()
> 
> 
> 
> base::assign(".dptime", (proc.time() - get(".ptime", pos = "CheckExEnv")), pos = "CheckExEnv")
> base::cat("update.dev.pkg", base::get(".format_ptime", pos = 'CheckExEnv')(get(".dptime", pos = "CheckExEnv")), "\n", file=base::get(".ExTimings", pos = 'CheckExEnv'), append=TRUE, sep="\t")
> ### * <FOOTER>
> ###
> cleanEx()
> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  17.999 0.504 2.555 0.001 0.001 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
